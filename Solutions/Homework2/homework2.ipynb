{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.4.0'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing, normalizing and bootstrapping data\n",
    "\n",
    "We are loading the data from `npz` numpy zip, splitting the training in train and validation sets and parsing those to tensor datasets for training pytorch models  \n",
    "\n",
    "**TODO**: Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_set = np.load('./prediction-challenge-01-data.npz')\n",
    "\n",
    "X, y, test = data_set['data_x'], data_set['data_y'], data_set['test_x']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's try some bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff652747518>"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff652491780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy import ndimage\n",
    "plt.imshow(ndimage.rotate(X[0][0], 65, reshape=False), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 1, 28, 28)\n",
      "(20000,)\n"
     ]
    }
   ],
   "source": [
    "mean_image = np.mean(X, axis=0)\n",
    "X -= mean_image\n",
    "test -= mean_image\n",
    "train_x, validation_x, train_y, validation_y = train_test_split(X, y, test_size=.2)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rotate\n",
    "\n",
    "Let's rotate the images a little bit in order to gain some more training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_x = train_x\n",
    "new_y = train_y\n",
    "for deg in range(15, 61, 15):\n",
    "    new_data = []\n",
    "    new_labels = y\n",
    "    for i, x in enumerate(X):\n",
    "        new_data.append([ndimage.rotate(x[0], 65, reshape=False)])\n",
    "        \n",
    "    new_x = np.vstack([new_x, new_data])\n",
    "    new_y = np.append(new_y, new_labels)\n",
    "train_x = new_x\n",
    "train_y = new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data: (96000, 1, 28, 28)\n",
      "Labels' shape: (96000,)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = data_utils.TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "validation_dataset = data_utils.TensorDataset(torch.from_numpy(validation_x), torch.from_numpy(validation_y))\n",
    "\n",
    "# to make sure everything is fine\n",
    "print('Shape of training data: {}'.format(train_x.shape))\n",
    "print('Labels\\' shape: {}'.format(train_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing data\n",
    "\n",
    "It's always good to know how our data looks like and what the corresponding labels are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAELRJREFUeJzt3X+MlfWVx/HPEZFhZiSCXSyhrFYD\nZlUiNRN/RFzcGNA2TbSJ1WJs2NiU/lHiNukfa/SP+s8mZrO1yx+bmukKhdhKG+uvGLJqzBqXZNMw\nqKl0WZQgWlZkMBoLyKDA2T/m0ow693vG+9x7nwvn/UrMzNxzH+65d+bjM3fO8zxfc3cByOeMuhsA\nUA/CDyRF+IGkCD+QFOEHkiL8QFKEH0iK8ANJEX4gqTO7+WAzZszwwcHBbj4kkMqhQ4d09OhRm8p9\nK4XfzG6StFbSNEn/7u4PlO4/ODioG2+8scpDAih49tlnp3zfln/tN7Npkv5N0tclXSJppZld0uq/\nB6C7qrznv1LSLnff7e4fS9ok6eb2tAWg06qEf76kP034em/jtk8xs9VmNmJmI2NjYxUeDkA7VQn/\nZH9U+Nz5we4+7O5D7j7U19dX4eEAtFOV8O+VtGDC11+R9E61dgB0S5Xwb5W00My+amZnSfqOpKfb\n0xaATmt51Ofux8xsjaRnNT7qW+fuf2xbZwA6qtKc3903S9rcpl4AdBGH9wJJEX4gKcIPJEX4gaQI\nP5AU4QeS6ur5/OiMCy+8sGntvvvuK247c+bMYv25554r1tevX1+sd5LZlE5bRxPs+YGkCD+QFOEH\nkiL8QFKEH0iK8ANJMeo7Bbh/7gJJn7Jo0aKmtbPOOqu47SeffFKsL168uFg/evRosV5yxhnlfU80\nyou2L9UZE7LnB9Ii/EBShB9IivADSRF+ICnCDyRF+IGkmPN3wYkTJyrV58yZU6wvW7asae3gwYPF\nbT/++ONi/b333ivWDxw4UKyXTJ8+vbb6mWeWf/SnTZtWrEfHGJwKTv1nAKAlhB9IivADSRF+ICnC\nDyRF+IGkCD+QVKU5v5ntkXRQ0nFJx9x9qB1N9aLSOfXRnD46Z76vr69YX7NmTbFemkmPjo4Wtz1y\n5Eix/sYbbxTrb7/9drFemodHs/b+/v5K9YGBgaa16JLlVY8xqHqtgm5ox0E+f+fu5SNBAPQcfu0H\nkqoafpf0nJltM7PV7WgIQHdU/bX/Wnd/x8zmSnrezP7X3V+aeIfG/xRWS/F7NADdU2nP7+7vND6O\nSnpC0pWT3GfY3YfcfSj6wxaA7mk5/GY2YGZnn/xc0gpJ29vVGIDOqvJr/3mSnmiMLM6U9Gt3/4+2\ndAWg41oOv7vvlnR5G3upVXRt/NIsP5rjR+fMV513f/DBB01r0fn8hw8fLtYfeuihYj06jqA0747W\nFIie96xZs4r10vcsOjajdIzAVETPrRfm/Iz6gKQIP5AU4QeSIvxAUoQfSIrwA0lx6e6GaNRXGudF\no76xsbFi/c477yzWo3FdqX7o0KHitps2bSrWX3zxxWI9GpmVRn3Hjx8vbht9T6LTZksj1Gi8Go3q\nou2rvC7dUn8HAGpB+IGkCD+QFOEHkiL8QFKEH0iK8ANJpZnzVzllN6pHc/5rrrmmWF+0aFGxXuW0\n3Oh04m3bthXrnTw1Ndo2+p4dO3asWC99X6Jto5+HqLdTAXt+ICnCDyRF+IGkCD+QFOEHkiL8QFKE\nH0iKOf8U66W5b3Re+tKlSys9dnQcQWn7119/vbjthx9+WKzPnj27WI+UXpvoeUU6eYxB1e174dLc\nEfb8QFKEH0iK8ANJEX4gKcIPJEX4gaQIP5BUOOc3s3WSvilp1N0va9w2R9JvJF0gaY+k29y9+TrR\nPaCTc9foGu6RqtevL52bHl13f8aMGcX6tGnTivWo96NHjxbrJdE59VFvpe9LtG10Xf0sc/5fSrrp\nM7fdI+kFd18o6YXG1wBOIWH43f0lSe9/5uabJW1ofL5B0i1t7gtAh7X6nv88d98nSY2Pc9vXEoBu\n6Pix/Wa2WtJqServ7+/0wwGYolb3/PvNbJ4kNT6ONrujuw+7+5C7D/X19bX4cADardXwPy1pVePz\nVZKeak87ALolDL+ZPSrpvyVdbGZ7zex7kh6QtNzM3pC0vPE1gFNI+J7f3Vc2Kd3Q5l56WmnWvmTJ\nkuK2CxYsKNajc+qjmfGWLVua1nbu3FncNrouf9Xr15fq0TEC0fOOjq8o1aNtozl/5HSZ8wM4DRF+\nICnCDyRF+IGkCD+QFOEHkkpz6e6qSiOrO+64o7htNNKqOvKqMpaKlqqOlviOTtkdGxtr+bGrnm48\nffr0lretOuqLRqC9MApkzw8kRfiBpAg/kBThB5Ii/EBShB9IivADSTHnb6iyRHc0r+70TPfxxx9v\nWot6i5bJLs3pJenIkSMt//vRLD063XjRokXF+sKFC5vWBgYGitvu2LGjWD8dsOcHkiL8QFKEH0iK\n8ANJEX4gKcIPJEX4gaSY8zdEl6gu1asuJR2JjhM4fPhw01p0rYCPPvqoWI/m+NH5/iVz5swp1u++\n++5ifdmyZcX6/Pnzm9YGBweL27777rvF+rp164r10dGmi1j1DPb8QFKEH0iK8ANJEX4gKcIPJEX4\ngaQIP5BUOOc3s3WSvilp1N0va9x2v6TvSzrQuNu97r65U032gtIsvzRnl6RzzjmnWI+Wi46UrkVQ\n9Xz+aPvI0NBQ09rtt99e3PaKK64o1qNZfZVjM84///xifcWKFcX6I488Uqz3gqns+X8p6aZJbv+Z\nuy9p/HdaBx84HYXhd/eXJL3fhV4AdFGV9/xrzOwPZrbOzGa3rSMAXdFq+H8u6SJJSyTtk/TTZnc0\ns9VmNmJmI9H14AB0T0vhd/f97n7c3U9I+oWkKwv3HXb3IXcf6uvra7VPAG3WUvjNbN6EL78laXt7\n2gHQLVMZ9T0q6XpJXzKzvZJ+Iul6M1siySXtkfSDDvYIoAPC8Lv7yklufrgDvdQqmvuWZulPPvlk\ncdu77rqrWC+tIy/F5/NfffXVTWtbtmwpbhsdYxBdOz9a7+DWW29tWrv00kuL20a9Ra9L1FuVfzs6\nDuBUwBF+QFKEH0iK8ANJEX4gKcIPJEX4gaTSXLo7GvtUGQtFl3mOLo/d399frEeX/r788sub1kZG\nRorbRiOtuXPnFutr164t1ku9R6O8aAnvSOm5Rf929LpcfPHFxfpVV11VrG/durVY7wb2/EBShB9I\nivADSRF+ICnCDyRF+IGkCD+QVJo5f5VTdqP6W2+9Vdx227Ztxfp1111XrEcz6eXLlzetRfPm6NJq\n0RLcVU6r7eSxF1LcW5Vtd+/eXay/8sorLT92t7DnB5Ii/EBShB9IivADSRF+ICnCDyRF+IGk0sz5\nq86Uqyz3vHHjxmI9WiZ76dKlxXrpvPizzz67uG10ae7oOIAqS3hXPac+us5B6XWpei2BzZvLC1NH\n39MqxyC0C3t+ICnCDyRF+IGkCD+QFOEHkiL8QFKEH0gqnPOb2QJJGyV9WdIJScPuvtbM5kj6jaQL\nJO2RdJu7f9C5Vqvp5Fw1Okbg8OHDxfrw8HCxHs3aFy9e3LQWLf8d/dvRvDp67qXHj2bpUe8zZsxo\nuX78+PHituvXry/Wt2/fXqz3whw/MpU9/zFJP3b3v5F0taQfmtklku6R9IK7L5T0QuNrAKeIMPzu\nvs/dX258flDSDknzJd0saUPjbhsk3dKpJgG03xd6z29mF0j6mqTfSzrP3fdJ4/+DkFRe1wlAT5ly\n+M1sUNLvJP3I3f/8BbZbbWYjZjYSvb8E0D1TCr+ZTdd48H/l7o83bt5vZvMa9XmSRifb1t2H3X3I\n3Yf6+vra0TOANgjDb+N/tnxY0g53f3BC6WlJqxqfr5L0VPvbA9ApUzml91pJ35X0mpm92rjtXkkP\nSPqtmX1P0tuSvt2ZFtuj6umhpXrVsU40CnzwwQeL9Xnz5jWtXXTRRcVtb7jhhmL93HPPLdajcVzp\nlOHoN8GBgYFiPfLYY481rUXLqu/atatYj35eToVRXxh+d98iqdkzKf/kAOhZHOEHJEX4gaQIP5AU\n4QeSIvxAUoQfSCrNpbuj00ejSzmXTg+NTnuNlrmuehnpN998s2lt586dxW2feeaZYj2aZ8+cObNY\nL106fNasWcVto3p0HEDpOILo+ITTYY4fYc8PJEX4gaQIP5AU4QeSIvxAUoQfSIrwA0mlmfNHc9lo\n1l46L72/v7+lnk7q5FLU0TEIkWgJ7+i5Dw4OtlST4mMIokt3l16X6DWNjq04HZz+zxDApAg/kBTh\nB5Ii/EBShB9IivADSRF+IKk0c/5INNctzbujmXE0K4/m2dF57aXrBURLUUei4x+qLKMdvS5Vjm+I\ntj8dzsevij0/kBThB5Ii/EBShB9IivADSRF+ICnCDyQVzvnNbIGkjZK+LOmEpGF3X2tm90v6vqQD\njbve6+6bO9Vo3UrHAUQz4+gYgmhWHh0H4O4t1aYiem5VrkUQvS5VH5tZftlUDvI5JunH7v6ymZ0t\naZuZPd+o/czd/6Vz7QHolDD87r5P0r7G5wfNbIek+Z1uDEBnfaH3/GZ2gaSvSfp946Y1ZvYHM1tn\nZrObbLPazEbMbGRsbKxSswDaZ8rhN7NBSb+T9CN3/7Okn0u6SNISjf9m8NPJtnP3YXcfcveh0tpp\nALprSuE3s+kaD/6v3P1xSXL3/e5+3N1PSPqFpCs71yaAdgvDb+N/Mn1Y0g53f3DC7fMm3O1bkra3\nvz0AnTKVv/ZfK+m7kl4zs1cbt90raaWZLZHkkvZI+kFHOjwFVL30djTyirYvqXvU16ltUd1U/tq/\nRdJk36XTdqYPZMARfkBShB9IivADSRF+ICnCDyRF+IGkuHR3D+DUVNSBPT+QFOEHkiL8QFKEH0iK\n8ANJEX4gKcIPJGVVz/f+Qg9mdkDSWxNu+pKk97rWwBfTq731al8SvbWqnb2d7+5/NZU7djX8n3tw\nsxF3H6qtgYJe7a1X+5LorVV19cav/UBShB9Iqu7wD9f8+CW92luv9iXRW6tq6a3W9/wA6lP3nh9A\nTWoJv5ndZGY7zWyXmd1TRw/NmNkeM3vNzF41s5Gae1lnZqNmtn3CbXPM7Hkze6PxcdJl0mrq7X4z\n+7/Ga/eqmX2jpt4WmNl/mtkOM/ujmf1D4/ZaX7tCX7W8bl3/td/Mpkl6XdJySXslbZW00t3/p6uN\nNGFmeyQNuXvtM2Ez+1tJhyRtdPfLGrf9s6T33f2Bxv84Z7v7P/ZIb/dLOlT3ys2NBWXmTVxZWtIt\nkv5eNb52hb5uUw2vWx17/isl7XL33e7+saRNkm6uoY+e5+4vSXr/MzffLGlD4/MNGv/h6bomvfUE\nd9/n7i83Pj8o6eTK0rW+doW+alFH+OdL+tOEr/eqt5b8dknPmdk2M1tddzOTOK+xbPrJ5dPn1tzP\nZ4UrN3fTZ1aW7pnXrpUVr9utjvBPdk2qXho5XOvuV0j6uqQfNn69xdRMaeXmbplkZeme0OqK1+1W\nR/j3Slow4euvSHqnhj4m5e7vND6OSnpCvbf68P6Ti6Q2Po7W3M9f9NLKzZOtLK0eeO16acXrOsK/\nVdJCM/uqmZ0l6TuSnq6hj88xs4HGH2JkZgOSVqj3Vh9+WtKqxuerJD1VYy+f0isrNzdbWVo1v3a9\ntuJ1LQf5NEYZ/yppmqR17v5PXW9iEmZ2ocb39tL4lY1/XWdvZvaopOs1ftbXfkk/kfSkpN9K+mtJ\nb0v6trt3/Q9vTXq7XuO/uv5l5eaT77G73NtSSf8l6TVJJxo336vx99e1vXaFvlaqhteNI/yApDjC\nD0iK8ANJEX4gKcIPJEX4gaQIP5AU4QeSIvxAUv8PC6g3ZLu1GYgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff65272c400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_x[0][0], cmap='gray')\n",
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff652437e80>"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ntqAUgl0UsQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff6526d2320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(validation_y[0])\n",
    "plt.imshow(validation_x[0][0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff652536a20>"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA4Ui/EChCD9QKMIPFIrwA4X6P5FaTG2S+655AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff65269eef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mean_image[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "#### VGG\n",
    "\n",
    "As done in \"Mustererkennung\" course in WS17, we used VGG, though not VGG11\n",
    "\n",
    "We are using the VGG nets model. This is a pretty famous model and works great for recognizing images. Basic principle is to have some convolutional layers followed by pooling layers, the whole thing multiple times. Afterwards one usually has some number of fully connected layers, though this is originally not so in VGG. We decided to add the fully connected layers anyways, as we don't have the capcaity to run the original VGG model anyways.\n",
    "\n",
    "Further info -> http://www.robots.ox.ac.uk/~vgg/research/very_deep/\n",
    "\n",
    "#### Batchnorm, Dropout, Xavier\n",
    "\n",
    "Bachnorm makes training a model quicker as it keeps mean and standart deviation consistant within the network (if the model decides it's helpful for it, how much batch normalisation is used is a learning parameter). Dropout makes sure the NN doesn't overfit, as it repeatedly temporarily disables some neurons so better generalisation is reached. Xavier is used for better weights initialisation.\n",
    "\n",
    "#### First implementation\n",
    "\n",
    "Score 99.2%; No FC layers, 0.005 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "cfg = {\n",
    "    'VGG': [4, 8, 'M', 16, 16, 'M', 32, 32, 'M', 32, 32, 'M', 'FC', 64, 128, 32]\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG, self).__init__()\n",
    "        self.conv_layers, self.fc_layers = self._make_layers(cfg['VGG'])\n",
    "        self.classifier = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.fc_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)\n",
    "    \n",
    "    def _make_layers(self, cfg):\n",
    "        conv_layers = []\n",
    "        fc_layers = []\n",
    "        in_channels = 1\n",
    "        build_fc = False\n",
    "        \n",
    "        for x in cfg:\n",
    "            if build_fc:\n",
    "                fc = nn.Linear(in_channels, x)\n",
    "                fc_layers += [fc,\n",
    "                           nn.BatchNorm1d(x),\n",
    "                           nn.Dropout(p=0.05),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                nn.init.xavier_uniform_(fc.weight)\n",
    "            elif x == 'M':\n",
    "                conv_layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            elif x == 'FC':\n",
    "                build_fc = True\n",
    "            else:\n",
    "                conv = nn.Conv2d(in_channels, x, kernel_size=3, padding=1)\n",
    "                conv_layers += [conv,\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.Dropout(p=0.05),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                nn.init.xavier_uniform_(conv.weight)\n",
    "                \n",
    "            if isinstance(x, int):\n",
    "                in_channels = x\n",
    "        conv_layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "            \n",
    "        return nn.Sequential(*conv_layers), nn.Sequential(*fc_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VGG()\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {'num_workers': 1}\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True,\n",
    "                                           **kwargs)\n",
    "test_loader = torch.utils.data.DataLoader(validation_dataset,\n",
    "                                          batch_size=32,\n",
    "                                          shuffle=False,\n",
    "                                          **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(data)\n",
    "        \n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % 10 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        if torch.cuda.is_available():\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        test_loss += F.cross_entropy(output, target, size_average=False).item() # sum up batch loss\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/96000 (0%)]\tLoss: 0.100748\n",
      "Train Epoch: 1 [320/96000 (0%)]\tLoss: 0.432821\n",
      "Train Epoch: 1 [640/96000 (1%)]\tLoss: 0.009601\n",
      "Train Epoch: 1 [960/96000 (1%)]\tLoss: 0.007317\n",
      "Train Epoch: 1 [1280/96000 (1%)]\tLoss: 0.199081\n",
      "Train Epoch: 1 [1600/96000 (2%)]\tLoss: 0.092225\n",
      "Train Epoch: 1 [1920/96000 (2%)]\tLoss: 0.013636\n",
      "Train Epoch: 1 [2240/96000 (2%)]\tLoss: 0.002149\n",
      "Train Epoch: 1 [2560/96000 (3%)]\tLoss: 0.066231\n",
      "Train Epoch: 1 [2880/96000 (3%)]\tLoss: 0.005993\n",
      "Train Epoch: 1 [3200/96000 (3%)]\tLoss: 0.012264\n",
      "Train Epoch: 1 [3520/96000 (4%)]\tLoss: 0.001725\n",
      "Train Epoch: 1 [3840/96000 (4%)]\tLoss: 0.085416\n",
      "Train Epoch: 1 [4160/96000 (4%)]\tLoss: 0.001109\n",
      "Train Epoch: 1 [4480/96000 (5%)]\tLoss: 0.006493\n",
      "Train Epoch: 1 [4800/96000 (5%)]\tLoss: 0.025273\n",
      "Train Epoch: 1 [5120/96000 (5%)]\tLoss: 0.002262\n",
      "Train Epoch: 1 [5440/96000 (6%)]\tLoss: 0.050968\n",
      "Train Epoch: 1 [5760/96000 (6%)]\tLoss: 0.072761\n",
      "Train Epoch: 1 [6080/96000 (6%)]\tLoss: 0.035332\n",
      "Train Epoch: 1 [6400/96000 (7%)]\tLoss: 0.004667\n",
      "Train Epoch: 1 [6720/96000 (7%)]\tLoss: 0.015952\n",
      "Train Epoch: 1 [7040/96000 (7%)]\tLoss: 0.006196\n",
      "Train Epoch: 1 [7360/96000 (8%)]\tLoss: 0.005525\n",
      "Train Epoch: 1 [7680/96000 (8%)]\tLoss: 0.150659\n",
      "Train Epoch: 1 [8000/96000 (8%)]\tLoss: 0.004409\n",
      "Train Epoch: 1 [8320/96000 (9%)]\tLoss: 0.005752\n",
      "Train Epoch: 1 [8640/96000 (9%)]\tLoss: 0.063041\n",
      "Train Epoch: 1 [8960/96000 (9%)]\tLoss: 0.004391\n",
      "Train Epoch: 1 [9280/96000 (10%)]\tLoss: 0.025438\n",
      "Train Epoch: 1 [9600/96000 (10%)]\tLoss: 0.020727\n",
      "Train Epoch: 1 [9920/96000 (10%)]\tLoss: 0.023241\n",
      "Train Epoch: 1 [10240/96000 (11%)]\tLoss: 0.111687\n",
      "Train Epoch: 1 [10560/96000 (11%)]\tLoss: 0.001457\n",
      "Train Epoch: 1 [10880/96000 (11%)]\tLoss: 0.011512\n",
      "Train Epoch: 1 [11200/96000 (12%)]\tLoss: 0.098563\n",
      "Train Epoch: 1 [11520/96000 (12%)]\tLoss: 0.007319\n",
      "Train Epoch: 1 [11840/96000 (12%)]\tLoss: 0.000347\n",
      "Train Epoch: 1 [12160/96000 (13%)]\tLoss: 0.001002\n",
      "Train Epoch: 1 [12480/96000 (13%)]\tLoss: 0.022818\n",
      "Train Epoch: 1 [12800/96000 (13%)]\tLoss: 0.030846\n",
      "Train Epoch: 1 [13120/96000 (14%)]\tLoss: 0.023058\n",
      "Train Epoch: 1 [13440/96000 (14%)]\tLoss: 0.013419\n",
      "Train Epoch: 1 [13760/96000 (14%)]\tLoss: 0.019254\n",
      "Train Epoch: 1 [14080/96000 (15%)]\tLoss: 0.154406\n",
      "Train Epoch: 1 [14400/96000 (15%)]\tLoss: 0.004539\n",
      "Train Epoch: 1 [14720/96000 (15%)]\tLoss: 0.003926\n",
      "Train Epoch: 1 [15040/96000 (16%)]\tLoss: 0.019148\n",
      "Train Epoch: 1 [15360/96000 (16%)]\tLoss: 0.228551\n",
      "Train Epoch: 1 [15680/96000 (16%)]\tLoss: 0.013046\n",
      "Train Epoch: 1 [16000/96000 (17%)]\tLoss: 0.007538\n",
      "Train Epoch: 1 [16320/96000 (17%)]\tLoss: 0.001343\n",
      "Train Epoch: 1 [16640/96000 (17%)]\tLoss: 0.003013\n",
      "Train Epoch: 1 [16960/96000 (18%)]\tLoss: 0.235381\n",
      "Train Epoch: 1 [17280/96000 (18%)]\tLoss: 0.013060\n",
      "Train Epoch: 1 [17600/96000 (18%)]\tLoss: 0.047054\n",
      "Train Epoch: 1 [17920/96000 (19%)]\tLoss: 0.012054\n",
      "Train Epoch: 1 [18240/96000 (19%)]\tLoss: 0.019394\n",
      "Train Epoch: 1 [18560/96000 (19%)]\tLoss: 0.003324\n",
      "Train Epoch: 1 [18880/96000 (20%)]\tLoss: 0.009600\n",
      "Train Epoch: 1 [19200/96000 (20%)]\tLoss: 0.002985\n",
      "Train Epoch: 1 [19520/96000 (20%)]\tLoss: 0.041060\n",
      "Train Epoch: 1 [19840/96000 (21%)]\tLoss: 0.125433\n",
      "Train Epoch: 1 [20160/96000 (21%)]\tLoss: 0.073168\n",
      "Train Epoch: 1 [20480/96000 (21%)]\tLoss: 0.185242\n",
      "Train Epoch: 1 [20800/96000 (22%)]\tLoss: 0.001091\n",
      "Train Epoch: 1 [21120/96000 (22%)]\tLoss: 0.004091\n",
      "Train Epoch: 1 [21440/96000 (22%)]\tLoss: 0.002429\n",
      "Train Epoch: 1 [21760/96000 (23%)]\tLoss: 0.001607\n",
      "Train Epoch: 1 [22080/96000 (23%)]\tLoss: 0.006057\n",
      "Train Epoch: 1 [22400/96000 (23%)]\tLoss: 0.264680\n",
      "Train Epoch: 1 [22720/96000 (24%)]\tLoss: 0.127903\n",
      "Train Epoch: 1 [23040/96000 (24%)]\tLoss: 0.051673\n",
      "Train Epoch: 1 [23360/96000 (24%)]\tLoss: 0.001134\n",
      "Train Epoch: 1 [23680/96000 (25%)]\tLoss: 0.009246\n",
      "Train Epoch: 1 [24000/96000 (25%)]\tLoss: 0.089892\n",
      "Train Epoch: 1 [24320/96000 (25%)]\tLoss: 0.002841\n",
      "Train Epoch: 1 [24640/96000 (26%)]\tLoss: 0.002366\n",
      "Train Epoch: 1 [24960/96000 (26%)]\tLoss: 0.015413\n",
      "Train Epoch: 1 [25280/96000 (26%)]\tLoss: 0.026193\n",
      "Train Epoch: 1 [25600/96000 (27%)]\tLoss: 0.007455\n",
      "Train Epoch: 1 [25920/96000 (27%)]\tLoss: 0.001464\n",
      "Train Epoch: 1 [26240/96000 (27%)]\tLoss: 0.010843\n",
      "Train Epoch: 1 [26560/96000 (28%)]\tLoss: 0.008705\n",
      "Train Epoch: 1 [26880/96000 (28%)]\tLoss: 0.032737\n",
      "Train Epoch: 1 [27200/96000 (28%)]\tLoss: 0.029177\n",
      "Train Epoch: 1 [27520/96000 (29%)]\tLoss: 0.001961\n",
      "Train Epoch: 1 [27840/96000 (29%)]\tLoss: 0.006391\n",
      "Train Epoch: 1 [28160/96000 (29%)]\tLoss: 0.011632\n",
      "Train Epoch: 1 [28480/96000 (30%)]\tLoss: 0.001183\n",
      "Train Epoch: 1 [28800/96000 (30%)]\tLoss: 0.053268\n",
      "Train Epoch: 1 [29120/96000 (30%)]\tLoss: 0.003414\n",
      "Train Epoch: 1 [29440/96000 (31%)]\tLoss: 0.003889\n",
      "Train Epoch: 1 [29760/96000 (31%)]\tLoss: 0.025717\n",
      "Train Epoch: 1 [30080/96000 (31%)]\tLoss: 0.001859\n",
      "Train Epoch: 1 [30400/96000 (32%)]\tLoss: 0.098287\n",
      "Train Epoch: 1 [30720/96000 (32%)]\tLoss: 0.007551\n",
      "Train Epoch: 1 [31040/96000 (32%)]\tLoss: 0.003513\n",
      "Train Epoch: 1 [31360/96000 (33%)]\tLoss: 0.014061\n",
      "Train Epoch: 1 [31680/96000 (33%)]\tLoss: 0.025604\n",
      "Train Epoch: 1 [32000/96000 (33%)]\tLoss: 0.002748\n",
      "Train Epoch: 1 [32320/96000 (34%)]\tLoss: 0.028312\n",
      "Train Epoch: 1 [32640/96000 (34%)]\tLoss: 0.157431\n",
      "Train Epoch: 1 [32960/96000 (34%)]\tLoss: 0.039384\n",
      "Train Epoch: 1 [33280/96000 (35%)]\tLoss: 0.004314\n",
      "Train Epoch: 1 [33600/96000 (35%)]\tLoss: 0.008337\n",
      "Train Epoch: 1 [33920/96000 (35%)]\tLoss: 0.026340\n",
      "Train Epoch: 1 [34240/96000 (36%)]\tLoss: 0.013168\n",
      "Train Epoch: 1 [34560/96000 (36%)]\tLoss: 0.013114\n",
      "Train Epoch: 1 [34880/96000 (36%)]\tLoss: 0.007498\n",
      "Train Epoch: 1 [35200/96000 (37%)]\tLoss: 0.031796\n",
      "Train Epoch: 1 [35520/96000 (37%)]\tLoss: 0.002830\n",
      "Train Epoch: 1 [35840/96000 (37%)]\tLoss: 0.003589\n",
      "Train Epoch: 1 [36160/96000 (38%)]\tLoss: 0.013835\n",
      "Train Epoch: 1 [36480/96000 (38%)]\tLoss: 0.127818\n",
      "Train Epoch: 1 [36800/96000 (38%)]\tLoss: 0.099556\n",
      "Train Epoch: 1 [37120/96000 (39%)]\tLoss: 0.010023\n",
      "Train Epoch: 1 [37440/96000 (39%)]\tLoss: 0.120413\n",
      "Train Epoch: 1 [37760/96000 (39%)]\tLoss: 0.018535\n",
      "Train Epoch: 1 [38080/96000 (40%)]\tLoss: 0.012665\n",
      "Train Epoch: 1 [38400/96000 (40%)]\tLoss: 0.019603\n",
      "Train Epoch: 1 [38720/96000 (40%)]\tLoss: 0.030401\n",
      "Train Epoch: 1 [39040/96000 (41%)]\tLoss: 0.298986\n",
      "Train Epoch: 1 [39360/96000 (41%)]\tLoss: 0.155178\n",
      "Train Epoch: 1 [39680/96000 (41%)]\tLoss: 0.005318\n",
      "Train Epoch: 1 [40000/96000 (42%)]\tLoss: 0.044117\n",
      "Train Epoch: 1 [40320/96000 (42%)]\tLoss: 0.027631\n",
      "Train Epoch: 1 [40640/96000 (42%)]\tLoss: 0.001756\n",
      "Train Epoch: 1 [40960/96000 (43%)]\tLoss: 0.005018\n",
      "Train Epoch: 1 [41280/96000 (43%)]\tLoss: 0.014353\n",
      "Train Epoch: 1 [41600/96000 (43%)]\tLoss: 0.237410\n",
      "Train Epoch: 1 [41920/96000 (44%)]\tLoss: 0.000640\n",
      "Train Epoch: 1 [42240/96000 (44%)]\tLoss: 0.003345\n",
      "Train Epoch: 1 [42560/96000 (44%)]\tLoss: 0.001667\n",
      "Train Epoch: 1 [42880/96000 (45%)]\tLoss: 0.001282\n",
      "Train Epoch: 1 [43200/96000 (45%)]\tLoss: 0.335751\n",
      "Train Epoch: 1 [43520/96000 (45%)]\tLoss: 0.105214\n",
      "Train Epoch: 1 [43840/96000 (46%)]\tLoss: 0.000892\n",
      "Train Epoch: 1 [44160/96000 (46%)]\tLoss: 0.017217\n",
      "Train Epoch: 1 [44480/96000 (46%)]\tLoss: 0.000397\n",
      "Train Epoch: 1 [44800/96000 (47%)]\tLoss: 0.124120\n",
      "Train Epoch: 1 [45120/96000 (47%)]\tLoss: 0.001529\n",
      "Train Epoch: 1 [45440/96000 (47%)]\tLoss: 0.044491\n",
      "Train Epoch: 1 [45760/96000 (48%)]\tLoss: 0.001179\n",
      "Train Epoch: 1 [46080/96000 (48%)]\tLoss: 0.003659\n",
      "Train Epoch: 1 [46400/96000 (48%)]\tLoss: 0.006789\n",
      "Train Epoch: 1 [46720/96000 (49%)]\tLoss: 0.049071\n",
      "Train Epoch: 1 [47040/96000 (49%)]\tLoss: 0.059468\n",
      "Train Epoch: 1 [47360/96000 (49%)]\tLoss: 0.233494\n",
      "Train Epoch: 1 [47680/96000 (50%)]\tLoss: 0.046142\n",
      "Train Epoch: 1 [48000/96000 (50%)]\tLoss: 0.072907\n",
      "Train Epoch: 1 [48320/96000 (50%)]\tLoss: 0.068657\n",
      "Train Epoch: 1 [48640/96000 (51%)]\tLoss: 0.047143\n",
      "Train Epoch: 1 [48960/96000 (51%)]\tLoss: 0.001191\n",
      "Train Epoch: 1 [49280/96000 (51%)]\tLoss: 0.000691\n",
      "Train Epoch: 1 [49600/96000 (52%)]\tLoss: 0.022536\n",
      "Train Epoch: 1 [49920/96000 (52%)]\tLoss: 0.020133\n",
      "Train Epoch: 1 [50240/96000 (52%)]\tLoss: 0.020842\n",
      "Train Epoch: 1 [50560/96000 (53%)]\tLoss: 0.001606\n",
      "Train Epoch: 1 [50880/96000 (53%)]\tLoss: 0.039627\n",
      "Train Epoch: 1 [51200/96000 (53%)]\tLoss: 0.071177\n",
      "Train Epoch: 1 [51520/96000 (54%)]\tLoss: 0.000995\n",
      "Train Epoch: 1 [51840/96000 (54%)]\tLoss: 0.000820\n",
      "Train Epoch: 1 [52160/96000 (54%)]\tLoss: 0.044575\n",
      "Train Epoch: 1 [52480/96000 (55%)]\tLoss: 0.008167\n",
      "Train Epoch: 1 [52800/96000 (55%)]\tLoss: 0.051070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [53120/96000 (55%)]\tLoss: 0.000512\n",
      "Train Epoch: 1 [53440/96000 (56%)]\tLoss: 0.123928\n",
      "Train Epoch: 1 [53760/96000 (56%)]\tLoss: 0.024254\n",
      "Train Epoch: 1 [54080/96000 (56%)]\tLoss: 0.009468\n",
      "Train Epoch: 1 [54400/96000 (57%)]\tLoss: 0.007951\n",
      "Train Epoch: 1 [54720/96000 (57%)]\tLoss: 0.000616\n",
      "Train Epoch: 1 [55040/96000 (57%)]\tLoss: 0.116020\n",
      "Train Epoch: 1 [55360/96000 (58%)]\tLoss: 0.000852\n",
      "Train Epoch: 1 [55680/96000 (58%)]\tLoss: 0.004461\n",
      "Train Epoch: 1 [56000/96000 (58%)]\tLoss: 0.025699\n",
      "Train Epoch: 1 [56320/96000 (59%)]\tLoss: 0.003339\n",
      "Train Epoch: 1 [56640/96000 (59%)]\tLoss: 0.034453\n",
      "Train Epoch: 1 [56960/96000 (59%)]\tLoss: 0.122226\n",
      "Train Epoch: 1 [57280/96000 (60%)]\tLoss: 0.012836\n",
      "Train Epoch: 1 [57600/96000 (60%)]\tLoss: 0.006663\n",
      "Train Epoch: 1 [57920/96000 (60%)]\tLoss: 0.003938\n",
      "Train Epoch: 1 [58240/96000 (61%)]\tLoss: 0.002040\n",
      "Train Epoch: 1 [58560/96000 (61%)]\tLoss: 0.002250\n",
      "Train Epoch: 1 [58880/96000 (61%)]\tLoss: 0.152589\n",
      "Train Epoch: 1 [59200/96000 (62%)]\tLoss: 0.004307\n",
      "Train Epoch: 1 [59520/96000 (62%)]\tLoss: 0.003977\n",
      "Train Epoch: 1 [59840/96000 (62%)]\tLoss: 0.002808\n",
      "Train Epoch: 1 [60160/96000 (63%)]\tLoss: 0.006369\n",
      "Train Epoch: 1 [60480/96000 (63%)]\tLoss: 0.001505\n",
      "Train Epoch: 1 [60800/96000 (63%)]\tLoss: 0.088933\n",
      "Train Epoch: 1 [61120/96000 (64%)]\tLoss: 0.029502\n",
      "Train Epoch: 1 [61440/96000 (64%)]\tLoss: 0.196175\n",
      "Train Epoch: 1 [61760/96000 (64%)]\tLoss: 0.026967\n",
      "Train Epoch: 1 [62080/96000 (65%)]\tLoss: 0.080666\n",
      "Train Epoch: 1 [62400/96000 (65%)]\tLoss: 0.003989\n",
      "Train Epoch: 1 [62720/96000 (65%)]\tLoss: 0.009093\n",
      "Train Epoch: 1 [63040/96000 (66%)]\tLoss: 0.001062\n",
      "Train Epoch: 1 [63360/96000 (66%)]\tLoss: 0.001904\n",
      "Train Epoch: 1 [63680/96000 (66%)]\tLoss: 0.195075\n",
      "Train Epoch: 1 [64000/96000 (67%)]\tLoss: 0.305289\n",
      "Train Epoch: 1 [64320/96000 (67%)]\tLoss: 0.055019\n",
      "Train Epoch: 1 [64640/96000 (67%)]\tLoss: 0.003367\n",
      "Train Epoch: 1 [64960/96000 (68%)]\tLoss: 0.051776\n",
      "Train Epoch: 1 [65280/96000 (68%)]\tLoss: 0.001313\n",
      "Train Epoch: 1 [65600/96000 (68%)]\tLoss: 0.006844\n",
      "Train Epoch: 1 [65920/96000 (69%)]\tLoss: 0.210085\n",
      "Train Epoch: 1 [66240/96000 (69%)]\tLoss: 0.005238\n",
      "Train Epoch: 1 [66560/96000 (69%)]\tLoss: 0.015563\n",
      "Train Epoch: 1 [66880/96000 (70%)]\tLoss: 0.017803\n",
      "Train Epoch: 1 [67200/96000 (70%)]\tLoss: 0.006554\n",
      "Train Epoch: 1 [67520/96000 (70%)]\tLoss: 0.006332\n",
      "Train Epoch: 1 [67840/96000 (71%)]\tLoss: 0.020377\n",
      "Train Epoch: 1 [68160/96000 (71%)]\tLoss: 0.065112\n",
      "Train Epoch: 1 [68480/96000 (71%)]\tLoss: 0.007230\n",
      "Train Epoch: 1 [68800/96000 (72%)]\tLoss: 0.007277\n",
      "Train Epoch: 1 [69120/96000 (72%)]\tLoss: 0.267864\n",
      "Train Epoch: 1 [69440/96000 (72%)]\tLoss: 0.020429\n",
      "Train Epoch: 1 [69760/96000 (73%)]\tLoss: 0.032451\n",
      "Train Epoch: 1 [70080/96000 (73%)]\tLoss: 0.000980\n",
      "Train Epoch: 1 [70400/96000 (73%)]\tLoss: 0.014907\n",
      "Train Epoch: 1 [70720/96000 (74%)]\tLoss: 0.003219\n",
      "Train Epoch: 1 [71040/96000 (74%)]\tLoss: 0.018781\n",
      "Train Epoch: 1 [71360/96000 (74%)]\tLoss: 0.152170\n",
      "Train Epoch: 1 [71680/96000 (75%)]\tLoss: 0.007065\n",
      "Train Epoch: 1 [72000/96000 (75%)]\tLoss: 0.007463\n",
      "Train Epoch: 1 [72320/96000 (75%)]\tLoss: 0.012994\n",
      "Train Epoch: 1 [72640/96000 (76%)]\tLoss: 0.061189\n",
      "Train Epoch: 1 [72960/96000 (76%)]\tLoss: 0.150438\n",
      "Train Epoch: 1 [73280/96000 (76%)]\tLoss: 0.001401\n",
      "Train Epoch: 1 [73600/96000 (77%)]\tLoss: 0.001238\n",
      "Train Epoch: 1 [73920/96000 (77%)]\tLoss: 0.001189\n",
      "Train Epoch: 1 [74240/96000 (77%)]\tLoss: 0.325973\n",
      "Train Epoch: 1 [74560/96000 (78%)]\tLoss: 0.002669\n",
      "Train Epoch: 1 [74880/96000 (78%)]\tLoss: 0.129319\n",
      "Train Epoch: 1 [75200/96000 (78%)]\tLoss: 0.164862\n",
      "Train Epoch: 1 [75520/96000 (79%)]\tLoss: 0.000781\n",
      "Train Epoch: 1 [75840/96000 (79%)]\tLoss: 0.003601\n",
      "Train Epoch: 1 [76160/96000 (79%)]\tLoss: 0.000939\n",
      "Train Epoch: 1 [76480/96000 (80%)]\tLoss: 0.017309\n",
      "Train Epoch: 1 [76800/96000 (80%)]\tLoss: 0.019035\n",
      "Train Epoch: 1 [77120/96000 (80%)]\tLoss: 0.043903\n",
      "Train Epoch: 1 [77440/96000 (81%)]\tLoss: 0.009673\n",
      "Train Epoch: 1 [77760/96000 (81%)]\tLoss: 0.002444\n",
      "Train Epoch: 1 [78080/96000 (81%)]\tLoss: 0.035744\n",
      "Train Epoch: 1 [78400/96000 (82%)]\tLoss: 0.004501\n",
      "Train Epoch: 1 [78720/96000 (82%)]\tLoss: 0.001153\n",
      "Train Epoch: 1 [79040/96000 (82%)]\tLoss: 0.002681\n",
      "Train Epoch: 1 [79360/96000 (83%)]\tLoss: 0.008359\n",
      "Train Epoch: 1 [79680/96000 (83%)]\tLoss: 0.002107\n",
      "Train Epoch: 1 [80000/96000 (83%)]\tLoss: 0.022175\n",
      "Train Epoch: 1 [80320/96000 (84%)]\tLoss: 0.000455\n",
      "Train Epoch: 1 [80640/96000 (84%)]\tLoss: 0.082851\n",
      "Train Epoch: 1 [80960/96000 (84%)]\tLoss: 0.007648\n",
      "Train Epoch: 1 [81280/96000 (85%)]\tLoss: 0.083534\n",
      "Train Epoch: 1 [81600/96000 (85%)]\tLoss: 0.000743\n",
      "Train Epoch: 1 [81920/96000 (85%)]\tLoss: 0.001757\n",
      "Train Epoch: 1 [82240/96000 (86%)]\tLoss: 0.131619\n",
      "Train Epoch: 1 [82560/96000 (86%)]\tLoss: 0.060683\n",
      "Train Epoch: 1 [82880/96000 (86%)]\tLoss: 0.025062\n",
      "Train Epoch: 1 [83200/96000 (87%)]\tLoss: 0.027718\n",
      "Train Epoch: 1 [83520/96000 (87%)]\tLoss: 0.000821\n",
      "Train Epoch: 1 [83840/96000 (87%)]\tLoss: 0.017164\n",
      "Train Epoch: 1 [84160/96000 (88%)]\tLoss: 0.007656\n",
      "Train Epoch: 1 [84480/96000 (88%)]\tLoss: 0.006625\n",
      "Train Epoch: 1 [84800/96000 (88%)]\tLoss: 0.000829\n",
      "Train Epoch: 1 [85120/96000 (89%)]\tLoss: 0.002365\n",
      "Train Epoch: 1 [85440/96000 (89%)]\tLoss: 0.002722\n",
      "Train Epoch: 1 [85760/96000 (89%)]\tLoss: 0.011250\n",
      "Train Epoch: 1 [86080/96000 (90%)]\tLoss: 0.024105\n",
      "Train Epoch: 1 [86400/96000 (90%)]\tLoss: 0.006004\n",
      "Train Epoch: 1 [86720/96000 (90%)]\tLoss: 0.082207\n",
      "Train Epoch: 1 [87040/96000 (91%)]\tLoss: 0.106819\n",
      "Train Epoch: 1 [87360/96000 (91%)]\tLoss: 0.017172\n",
      "Train Epoch: 1 [87680/96000 (91%)]\tLoss: 0.001152\n",
      "Train Epoch: 1 [88000/96000 (92%)]\tLoss: 0.095525\n",
      "Train Epoch: 1 [88320/96000 (92%)]\tLoss: 0.002547\n",
      "Train Epoch: 1 [88640/96000 (92%)]\tLoss: 0.007596\n",
      "Train Epoch: 1 [88960/96000 (93%)]\tLoss: 0.042561\n",
      "Train Epoch: 1 [89280/96000 (93%)]\tLoss: 0.001864\n",
      "Train Epoch: 1 [89600/96000 (93%)]\tLoss: 0.003727\n",
      "Train Epoch: 1 [89920/96000 (94%)]\tLoss: 0.098717\n",
      "Train Epoch: 1 [90240/96000 (94%)]\tLoss: 0.196628\n",
      "Train Epoch: 1 [90560/96000 (94%)]\tLoss: 0.003189\n",
      "Train Epoch: 1 [90880/96000 (95%)]\tLoss: 0.030416\n",
      "Train Epoch: 1 [91200/96000 (95%)]\tLoss: 0.004711\n",
      "Train Epoch: 1 [91520/96000 (95%)]\tLoss: 0.014294\n",
      "Train Epoch: 1 [91840/96000 (96%)]\tLoss: 0.011239\n",
      "Train Epoch: 1 [92160/96000 (96%)]\tLoss: 0.001504\n",
      "Train Epoch: 1 [92480/96000 (96%)]\tLoss: 0.002835\n",
      "Train Epoch: 1 [92800/96000 (97%)]\tLoss: 0.021039\n",
      "Train Epoch: 1 [93120/96000 (97%)]\tLoss: 0.005862\n",
      "Train Epoch: 1 [93440/96000 (97%)]\tLoss: 0.020933\n",
      "Train Epoch: 1 [93760/96000 (98%)]\tLoss: 0.008310\n",
      "Train Epoch: 1 [94080/96000 (98%)]\tLoss: 0.004036\n",
      "Train Epoch: 1 [94400/96000 (98%)]\tLoss: 0.070274\n",
      "Train Epoch: 1 [94720/96000 (99%)]\tLoss: 0.007145\n",
      "Train Epoch: 1 [95040/96000 (99%)]\tLoss: 0.001387\n",
      "Train Epoch: 1 [95360/96000 (99%)]\tLoss: 0.124111\n",
      "Train Epoch: 1 [95680/96000 (100%)]\tLoss: 0.006183\n",
      "\n",
      "Test set: Average loss: 0.0672, Accuracy: 3926/4000 (98.000%)\n",
      "\n",
      "Train Epoch: 2 [0/96000 (0%)]\tLoss: 0.002314\n",
      "Train Epoch: 2 [320/96000 (0%)]\tLoss: 0.001134\n",
      "Train Epoch: 2 [640/96000 (1%)]\tLoss: 0.002238\n",
      "Train Epoch: 2 [960/96000 (1%)]\tLoss: 0.049265\n",
      "Train Epoch: 2 [1280/96000 (1%)]\tLoss: 0.001099\n",
      "Train Epoch: 2 [1600/96000 (2%)]\tLoss: 0.013158\n",
      "Train Epoch: 2 [1920/96000 (2%)]\tLoss: 0.003344\n",
      "Train Epoch: 2 [2240/96000 (2%)]\tLoss: 0.070267\n",
      "Train Epoch: 2 [2560/96000 (3%)]\tLoss: 0.003452\n",
      "Train Epoch: 2 [2880/96000 (3%)]\tLoss: 0.012931\n",
      "Train Epoch: 2 [3200/96000 (3%)]\tLoss: 0.040716\n",
      "Train Epoch: 2 [3520/96000 (4%)]\tLoss: 0.001547\n",
      "Train Epoch: 2 [3840/96000 (4%)]\tLoss: 0.012723\n",
      "Train Epoch: 2 [4160/96000 (4%)]\tLoss: 0.001493\n",
      "Train Epoch: 2 [4480/96000 (5%)]\tLoss: 0.001933\n",
      "Train Epoch: 2 [4800/96000 (5%)]\tLoss: 0.003225\n",
      "Train Epoch: 2 [5120/96000 (5%)]\tLoss: 0.009649\n",
      "Train Epoch: 2 [5440/96000 (6%)]\tLoss: 0.007394\n",
      "Train Epoch: 2 [5760/96000 (6%)]\tLoss: 0.000293\n",
      "Train Epoch: 2 [6080/96000 (6%)]\tLoss: 0.003859\n",
      "Train Epoch: 2 [6400/96000 (7%)]\tLoss: 0.006429\n",
      "Train Epoch: 2 [6720/96000 (7%)]\tLoss: 0.115198\n",
      "Train Epoch: 2 [7040/96000 (7%)]\tLoss: 0.001422\n",
      "Train Epoch: 2 [7360/96000 (8%)]\tLoss: 0.014195\n",
      "Train Epoch: 2 [7680/96000 (8%)]\tLoss: 0.033520\n",
      "Train Epoch: 2 [8000/96000 (8%)]\tLoss: 0.001290\n",
      "Train Epoch: 2 [8320/96000 (9%)]\tLoss: 0.006777\n",
      "Train Epoch: 2 [8640/96000 (9%)]\tLoss: 0.001181\n",
      "Train Epoch: 2 [8960/96000 (9%)]\tLoss: 0.001831\n",
      "Train Epoch: 2 [9280/96000 (10%)]\tLoss: 0.027628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [9600/96000 (10%)]\tLoss: 0.001511\n",
      "Train Epoch: 2 [9920/96000 (10%)]\tLoss: 0.001877\n",
      "Train Epoch: 2 [10240/96000 (11%)]\tLoss: 0.004117\n",
      "Train Epoch: 2 [10560/96000 (11%)]\tLoss: 0.026433\n",
      "Train Epoch: 2 [10880/96000 (11%)]\tLoss: 0.013807\n",
      "Train Epoch: 2 [11200/96000 (12%)]\tLoss: 0.013121\n",
      "Train Epoch: 2 [11520/96000 (12%)]\tLoss: 0.009292\n",
      "Train Epoch: 2 [11840/96000 (12%)]\tLoss: 0.017762\n",
      "Train Epoch: 2 [12160/96000 (13%)]\tLoss: 0.015861\n",
      "Train Epoch: 2 [12480/96000 (13%)]\tLoss: 0.001301\n",
      "Train Epoch: 2 [12800/96000 (13%)]\tLoss: 0.015147\n",
      "Train Epoch: 2 [13120/96000 (14%)]\tLoss: 0.002003\n",
      "Train Epoch: 2 [13440/96000 (14%)]\tLoss: 0.032141\n",
      "Train Epoch: 2 [13760/96000 (14%)]\tLoss: 0.053710\n",
      "Train Epoch: 2 [14080/96000 (15%)]\tLoss: 0.004993\n",
      "Train Epoch: 2 [14400/96000 (15%)]\tLoss: 0.023727\n",
      "Train Epoch: 2 [14720/96000 (15%)]\tLoss: 0.006545\n",
      "Train Epoch: 2 [15040/96000 (16%)]\tLoss: 0.000734\n",
      "Train Epoch: 2 [15360/96000 (16%)]\tLoss: 0.011745\n",
      "Train Epoch: 2 [15680/96000 (16%)]\tLoss: 0.000785\n",
      "Train Epoch: 2 [16000/96000 (17%)]\tLoss: 0.000608\n",
      "Train Epoch: 2 [16320/96000 (17%)]\tLoss: 0.147523\n",
      "Train Epoch: 2 [16640/96000 (17%)]\tLoss: 0.000980\n",
      "Train Epoch: 2 [16960/96000 (18%)]\tLoss: 0.002139\n",
      "Train Epoch: 2 [17280/96000 (18%)]\tLoss: 0.121331\n",
      "Train Epoch: 2 [17600/96000 (18%)]\tLoss: 0.000902\n",
      "Train Epoch: 2 [17920/96000 (19%)]\tLoss: 0.000661\n",
      "Train Epoch: 2 [18240/96000 (19%)]\tLoss: 0.025311\n",
      "Train Epoch: 2 [18560/96000 (19%)]\tLoss: 0.028411\n",
      "Train Epoch: 2 [18880/96000 (20%)]\tLoss: 0.001372\n",
      "Train Epoch: 2 [19200/96000 (20%)]\tLoss: 0.003121\n",
      "Train Epoch: 2 [19520/96000 (20%)]\tLoss: 0.000597\n",
      "Train Epoch: 2 [19840/96000 (21%)]\tLoss: 0.065047\n",
      "Train Epoch: 2 [20160/96000 (21%)]\tLoss: 0.003802\n",
      "Train Epoch: 2 [20480/96000 (21%)]\tLoss: 0.000409\n",
      "Train Epoch: 2 [20800/96000 (22%)]\tLoss: 0.002069\n",
      "Train Epoch: 2 [21120/96000 (22%)]\tLoss: 0.002714\n",
      "Train Epoch: 2 [21440/96000 (22%)]\tLoss: 0.015761\n",
      "Train Epoch: 2 [21760/96000 (23%)]\tLoss: 0.147189\n",
      "Train Epoch: 2 [22080/96000 (23%)]\tLoss: 0.007714\n",
      "Train Epoch: 2 [22400/96000 (23%)]\tLoss: 0.016082\n",
      "Train Epoch: 2 [22720/96000 (24%)]\tLoss: 0.006279\n",
      "Train Epoch: 2 [23040/96000 (24%)]\tLoss: 0.008627\n",
      "Train Epoch: 2 [23360/96000 (24%)]\tLoss: 0.000544\n",
      "Train Epoch: 2 [23680/96000 (25%)]\tLoss: 0.020298\n",
      "Train Epoch: 2 [24000/96000 (25%)]\tLoss: 0.071109\n",
      "Train Epoch: 2 [24320/96000 (25%)]\tLoss: 0.006388\n",
      "Train Epoch: 2 [24640/96000 (26%)]\tLoss: 0.002745\n",
      "Train Epoch: 2 [24960/96000 (26%)]\tLoss: 0.001152\n",
      "Train Epoch: 2 [25280/96000 (26%)]\tLoss: 0.004602\n",
      "Train Epoch: 2 [25600/96000 (27%)]\tLoss: 0.008476\n",
      "Train Epoch: 2 [25920/96000 (27%)]\tLoss: 0.001133\n",
      "Train Epoch: 2 [26240/96000 (27%)]\tLoss: 0.001960\n",
      "Train Epoch: 2 [26560/96000 (28%)]\tLoss: 0.312667\n",
      "Train Epoch: 2 [26880/96000 (28%)]\tLoss: 0.084222\n",
      "Train Epoch: 2 [27200/96000 (28%)]\tLoss: 0.001866\n",
      "Train Epoch: 2 [27520/96000 (29%)]\tLoss: 0.001453\n",
      "Train Epoch: 2 [27840/96000 (29%)]\tLoss: 0.015055\n",
      "Train Epoch: 2 [28160/96000 (29%)]\tLoss: 0.040344\n",
      "Train Epoch: 2 [28480/96000 (30%)]\tLoss: 0.001371\n",
      "Train Epoch: 2 [28800/96000 (30%)]\tLoss: 0.011789\n",
      "Train Epoch: 2 [29120/96000 (30%)]\tLoss: 0.000880\n",
      "Train Epoch: 2 [29440/96000 (31%)]\tLoss: 0.002411\n",
      "Train Epoch: 2 [29760/96000 (31%)]\tLoss: 0.009328\n",
      "Train Epoch: 2 [30080/96000 (31%)]\tLoss: 0.000697\n",
      "Train Epoch: 2 [30400/96000 (32%)]\tLoss: 0.080131\n",
      "Train Epoch: 2 [30720/96000 (32%)]\tLoss: 0.007158\n",
      "Train Epoch: 2 [31040/96000 (32%)]\tLoss: 0.003758\n",
      "Train Epoch: 2 [31360/96000 (33%)]\tLoss: 0.001356\n",
      "Train Epoch: 2 [31680/96000 (33%)]\tLoss: 0.044409\n",
      "Train Epoch: 2 [32000/96000 (33%)]\tLoss: 0.000814\n",
      "Train Epoch: 2 [32320/96000 (34%)]\tLoss: 0.005080\n",
      "Train Epoch: 2 [32640/96000 (34%)]\tLoss: 0.002871\n",
      "Train Epoch: 2 [32960/96000 (34%)]\tLoss: 0.001157\n",
      "Train Epoch: 2 [33280/96000 (35%)]\tLoss: 0.114520\n",
      "Train Epoch: 2 [33600/96000 (35%)]\tLoss: 0.002451\n",
      "Train Epoch: 2 [33920/96000 (35%)]\tLoss: 0.005296\n",
      "Train Epoch: 2 [34240/96000 (36%)]\tLoss: 0.002091\n",
      "Train Epoch: 2 [34560/96000 (36%)]\tLoss: 0.002896\n",
      "Train Epoch: 2 [34880/96000 (36%)]\tLoss: 0.002587\n",
      "Train Epoch: 2 [35200/96000 (37%)]\tLoss: 0.002231\n",
      "Train Epoch: 2 [35520/96000 (37%)]\tLoss: 0.007905\n",
      "Train Epoch: 2 [35840/96000 (37%)]\tLoss: 0.003292\n",
      "Train Epoch: 2 [36160/96000 (38%)]\tLoss: 0.010641\n",
      "Train Epoch: 2 [36480/96000 (38%)]\tLoss: 0.000767\n",
      "Train Epoch: 2 [36800/96000 (38%)]\tLoss: 0.004549\n",
      "Train Epoch: 2 [37120/96000 (39%)]\tLoss: 0.026690\n",
      "Train Epoch: 2 [37440/96000 (39%)]\tLoss: 0.002208\n",
      "Train Epoch: 2 [37760/96000 (39%)]\tLoss: 0.006964\n",
      "Train Epoch: 2 [38080/96000 (40%)]\tLoss: 0.015565\n",
      "Train Epoch: 2 [38400/96000 (40%)]\tLoss: 0.033242\n",
      "Train Epoch: 2 [38720/96000 (40%)]\tLoss: 0.001464\n",
      "Train Epoch: 2 [39040/96000 (41%)]\tLoss: 0.000527\n",
      "Train Epoch: 2 [39360/96000 (41%)]\tLoss: 0.084281\n",
      "Train Epoch: 2 [39680/96000 (41%)]\tLoss: 0.002172\n",
      "Train Epoch: 2 [40000/96000 (42%)]\tLoss: 0.010346\n",
      "Train Epoch: 2 [40320/96000 (42%)]\tLoss: 0.013607\n",
      "Train Epoch: 2 [40640/96000 (42%)]\tLoss: 0.003052\n",
      "Train Epoch: 2 [40960/96000 (43%)]\tLoss: 0.045077\n",
      "Train Epoch: 2 [41280/96000 (43%)]\tLoss: 0.006458\n",
      "Train Epoch: 2 [41600/96000 (43%)]\tLoss: 0.001877\n",
      "Train Epoch: 2 [41920/96000 (44%)]\tLoss: 0.015447\n",
      "Train Epoch: 2 [42240/96000 (44%)]\tLoss: 0.007914\n",
      "Train Epoch: 2 [42560/96000 (44%)]\tLoss: 0.001439\n",
      "Train Epoch: 2 [42880/96000 (45%)]\tLoss: 0.001125\n",
      "Train Epoch: 2 [43200/96000 (45%)]\tLoss: 0.000654\n",
      "Train Epoch: 2 [43520/96000 (45%)]\tLoss: 0.017037\n",
      "Train Epoch: 2 [43840/96000 (46%)]\tLoss: 0.016891\n",
      "Train Epoch: 2 [44160/96000 (46%)]\tLoss: 0.000496\n",
      "Train Epoch: 2 [44480/96000 (46%)]\tLoss: 0.051442\n",
      "Train Epoch: 2 [44800/96000 (47%)]\tLoss: 0.254187\n",
      "Train Epoch: 2 [45120/96000 (47%)]\tLoss: 0.004177\n",
      "Train Epoch: 2 [45440/96000 (47%)]\tLoss: 0.001042\n",
      "Train Epoch: 2 [45760/96000 (48%)]\tLoss: 0.000547\n",
      "Train Epoch: 2 [46080/96000 (48%)]\tLoss: 0.000334\n",
      "Train Epoch: 2 [46400/96000 (48%)]\tLoss: 0.008798\n",
      "Train Epoch: 2 [46720/96000 (49%)]\tLoss: 0.000517\n",
      "Train Epoch: 2 [47040/96000 (49%)]\tLoss: 0.194722\n",
      "Train Epoch: 2 [47360/96000 (49%)]\tLoss: 0.017303\n",
      "Train Epoch: 2 [47680/96000 (50%)]\tLoss: 0.000835\n",
      "Train Epoch: 2 [48000/96000 (50%)]\tLoss: 0.006349\n",
      "Train Epoch: 2 [48320/96000 (50%)]\tLoss: 0.001510\n",
      "Train Epoch: 2 [48640/96000 (51%)]\tLoss: 0.025459\n",
      "Train Epoch: 2 [48960/96000 (51%)]\tLoss: 0.007478\n",
      "Train Epoch: 2 [49280/96000 (51%)]\tLoss: 0.110514\n",
      "Train Epoch: 2 [49600/96000 (52%)]\tLoss: 0.010677\n",
      "Train Epoch: 2 [49920/96000 (52%)]\tLoss: 0.029778\n",
      "Train Epoch: 2 [50240/96000 (52%)]\tLoss: 0.054872\n",
      "Train Epoch: 2 [50560/96000 (53%)]\tLoss: 0.042104\n",
      "Train Epoch: 2 [50880/96000 (53%)]\tLoss: 0.282561\n",
      "Train Epoch: 2 [51200/96000 (53%)]\tLoss: 0.000939\n",
      "Train Epoch: 2 [51520/96000 (54%)]\tLoss: 0.002322\n",
      "Train Epoch: 2 [51840/96000 (54%)]\tLoss: 0.001243\n",
      "Train Epoch: 2 [52160/96000 (54%)]\tLoss: 0.000415\n",
      "Train Epoch: 2 [52480/96000 (55%)]\tLoss: 0.002681\n",
      "Train Epoch: 2 [52800/96000 (55%)]\tLoss: 0.001592\n",
      "Train Epoch: 2 [53120/96000 (55%)]\tLoss: 0.003767\n",
      "Train Epoch: 2 [53440/96000 (56%)]\tLoss: 0.000381\n",
      "Train Epoch: 2 [53760/96000 (56%)]\tLoss: 0.001202\n",
      "Train Epoch: 2 [54080/96000 (56%)]\tLoss: 0.004642\n",
      "Train Epoch: 2 [54400/96000 (57%)]\tLoss: 0.002620\n",
      "Train Epoch: 2 [54720/96000 (57%)]\tLoss: 0.007912\n",
      "Train Epoch: 2 [55040/96000 (57%)]\tLoss: 0.010869\n",
      "Train Epoch: 2 [55360/96000 (58%)]\tLoss: 0.001342\n",
      "Train Epoch: 2 [55680/96000 (58%)]\tLoss: 0.000842\n",
      "Train Epoch: 2 [56000/96000 (58%)]\tLoss: 0.002367\n",
      "Train Epoch: 2 [56320/96000 (59%)]\tLoss: 0.094425\n",
      "Train Epoch: 2 [56640/96000 (59%)]\tLoss: 0.001103\n",
      "Train Epoch: 2 [56960/96000 (59%)]\tLoss: 0.057624\n",
      "Train Epoch: 2 [57280/96000 (60%)]\tLoss: 0.050031\n",
      "Train Epoch: 2 [57600/96000 (60%)]\tLoss: 0.002445\n",
      "Train Epoch: 2 [57920/96000 (60%)]\tLoss: 0.003159\n",
      "Train Epoch: 2 [58240/96000 (61%)]\tLoss: 0.001193\n",
      "Train Epoch: 2 [58560/96000 (61%)]\tLoss: 0.144383\n",
      "Train Epoch: 2 [58880/96000 (61%)]\tLoss: 0.000779\n",
      "Train Epoch: 2 [59200/96000 (62%)]\tLoss: 0.056714\n",
      "Train Epoch: 2 [59520/96000 (62%)]\tLoss: 0.006128\n",
      "Train Epoch: 2 [59840/96000 (62%)]\tLoss: 0.000507\n",
      "Train Epoch: 2 [60160/96000 (63%)]\tLoss: 0.161524\n",
      "Train Epoch: 2 [60480/96000 (63%)]\tLoss: 0.000295\n",
      "Train Epoch: 2 [60800/96000 (63%)]\tLoss: 0.042489\n",
      "Train Epoch: 2 [61120/96000 (64%)]\tLoss: 0.004648\n",
      "Train Epoch: 2 [61440/96000 (64%)]\tLoss: 0.188129\n",
      "Train Epoch: 2 [61760/96000 (64%)]\tLoss: 0.002817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 2 [62080/96000 (65%)]\tLoss: 0.002579\n",
      "Train Epoch: 2 [62400/96000 (65%)]\tLoss: 0.002654\n",
      "Train Epoch: 2 [62720/96000 (65%)]\tLoss: 0.016055\n",
      "Train Epoch: 2 [63040/96000 (66%)]\tLoss: 0.002123\n",
      "Train Epoch: 2 [63360/96000 (66%)]\tLoss: 0.002469\n",
      "Train Epoch: 2 [63680/96000 (66%)]\tLoss: 0.007370\n",
      "Train Epoch: 2 [64000/96000 (67%)]\tLoss: 0.052708\n",
      "Train Epoch: 2 [64320/96000 (67%)]\tLoss: 0.025162\n",
      "Train Epoch: 2 [64640/96000 (67%)]\tLoss: 0.000632\n",
      "Train Epoch: 2 [64960/96000 (68%)]\tLoss: 0.023736\n",
      "Train Epoch: 2 [65280/96000 (68%)]\tLoss: 0.058434\n",
      "Train Epoch: 2 [65600/96000 (68%)]\tLoss: 0.147125\n",
      "Train Epoch: 2 [65920/96000 (69%)]\tLoss: 0.000861\n",
      "Train Epoch: 2 [66240/96000 (69%)]\tLoss: 0.023896\n",
      "Train Epoch: 2 [66560/96000 (69%)]\tLoss: 0.039122\n",
      "Train Epoch: 2 [66880/96000 (70%)]\tLoss: 0.000302\n",
      "Train Epoch: 2 [67200/96000 (70%)]\tLoss: 0.097103\n",
      "Train Epoch: 2 [67520/96000 (70%)]\tLoss: 0.004629\n",
      "Train Epoch: 2 [67840/96000 (71%)]\tLoss: 0.051326\n",
      "Train Epoch: 2 [68160/96000 (71%)]\tLoss: 0.000769\n",
      "Train Epoch: 2 [68480/96000 (71%)]\tLoss: 0.048576\n",
      "Train Epoch: 2 [68800/96000 (72%)]\tLoss: 0.000780\n",
      "Train Epoch: 2 [69120/96000 (72%)]\tLoss: 0.058461\n",
      "Train Epoch: 2 [69440/96000 (72%)]\tLoss: 0.011291\n",
      "Train Epoch: 2 [69760/96000 (73%)]\tLoss: 0.004162\n",
      "Train Epoch: 2 [70080/96000 (73%)]\tLoss: 0.001877\n",
      "Train Epoch: 2 [70400/96000 (73%)]\tLoss: 0.007599\n",
      "Train Epoch: 2 [70720/96000 (74%)]\tLoss: 0.000842\n",
      "Train Epoch: 2 [71040/96000 (74%)]\tLoss: 0.003198\n",
      "Train Epoch: 2 [71360/96000 (74%)]\tLoss: 0.001256\n",
      "Train Epoch: 2 [71680/96000 (75%)]\tLoss: 0.000889\n",
      "Train Epoch: 2 [72000/96000 (75%)]\tLoss: 0.267694\n",
      "Train Epoch: 2 [72320/96000 (75%)]\tLoss: 0.003181\n",
      "Train Epoch: 2 [72640/96000 (76%)]\tLoss: 0.004955\n",
      "Train Epoch: 2 [72960/96000 (76%)]\tLoss: 0.002670\n",
      "Train Epoch: 2 [73280/96000 (76%)]\tLoss: 0.009972\n",
      "Train Epoch: 2 [73600/96000 (77%)]\tLoss: 0.003112\n",
      "Train Epoch: 2 [73920/96000 (77%)]\tLoss: 0.007822\n",
      "Train Epoch: 2 [74240/96000 (77%)]\tLoss: 0.146077\n",
      "Train Epoch: 2 [74560/96000 (78%)]\tLoss: 0.004967\n",
      "Train Epoch: 2 [74880/96000 (78%)]\tLoss: 0.009876\n",
      "Train Epoch: 2 [75200/96000 (78%)]\tLoss: 0.121871\n",
      "Train Epoch: 2 [75520/96000 (79%)]\tLoss: 0.080360\n",
      "Train Epoch: 2 [75840/96000 (79%)]\tLoss: 0.003252\n",
      "Train Epoch: 2 [76160/96000 (79%)]\tLoss: 0.034761\n",
      "Train Epoch: 2 [76480/96000 (80%)]\tLoss: 0.000959\n",
      "Train Epoch: 2 [76800/96000 (80%)]\tLoss: 0.002801\n",
      "Train Epoch: 2 [77120/96000 (80%)]\tLoss: 0.007703\n",
      "Train Epoch: 2 [77440/96000 (81%)]\tLoss: 0.030078\n",
      "Train Epoch: 2 [77760/96000 (81%)]\tLoss: 0.002161\n",
      "Train Epoch: 2 [78080/96000 (81%)]\tLoss: 0.002062\n",
      "Train Epoch: 2 [78400/96000 (82%)]\tLoss: 0.009122\n",
      "Train Epoch: 2 [78720/96000 (82%)]\tLoss: 0.004642\n",
      "Train Epoch: 2 [79040/96000 (82%)]\tLoss: 0.124074\n",
      "Train Epoch: 2 [79360/96000 (83%)]\tLoss: 0.004468\n",
      "Train Epoch: 2 [79680/96000 (83%)]\tLoss: 0.001889\n",
      "Train Epoch: 2 [80000/96000 (83%)]\tLoss: 0.024537\n",
      "Train Epoch: 2 [80320/96000 (84%)]\tLoss: 0.001801\n",
      "Train Epoch: 2 [80640/96000 (84%)]\tLoss: 0.059568\n",
      "Train Epoch: 2 [80960/96000 (84%)]\tLoss: 0.169607\n",
      "Train Epoch: 2 [81280/96000 (85%)]\tLoss: 0.177933\n",
      "Train Epoch: 2 [81600/96000 (85%)]\tLoss: 0.002283\n",
      "Train Epoch: 2 [81920/96000 (85%)]\tLoss: 0.003186\n",
      "Train Epoch: 2 [82240/96000 (86%)]\tLoss: 0.000629\n",
      "Train Epoch: 2 [82560/96000 (86%)]\tLoss: 0.047553\n",
      "Train Epoch: 2 [82880/96000 (86%)]\tLoss: 0.000412\n",
      "Train Epoch: 2 [83200/96000 (87%)]\tLoss: 0.022296\n",
      "Train Epoch: 2 [83520/96000 (87%)]\tLoss: 0.002580\n",
      "Train Epoch: 2 [83840/96000 (87%)]\tLoss: 0.001858\n",
      "Train Epoch: 2 [84160/96000 (88%)]\tLoss: 0.001515\n",
      "Train Epoch: 2 [84480/96000 (88%)]\tLoss: 0.004206\n",
      "Train Epoch: 2 [84800/96000 (88%)]\tLoss: 0.000946\n",
      "Train Epoch: 2 [85120/96000 (89%)]\tLoss: 0.008739\n",
      "Train Epoch: 2 [85440/96000 (89%)]\tLoss: 0.017029\n",
      "Train Epoch: 2 [85760/96000 (89%)]\tLoss: 0.003899\n",
      "Train Epoch: 2 [86080/96000 (90%)]\tLoss: 0.026858\n",
      "Train Epoch: 2 [86400/96000 (90%)]\tLoss: 0.048185\n",
      "Train Epoch: 2 [86720/96000 (90%)]\tLoss: 0.001837\n",
      "Train Epoch: 2 [87040/96000 (91%)]\tLoss: 0.004609\n",
      "Train Epoch: 2 [87360/96000 (91%)]\tLoss: 0.002204\n",
      "Train Epoch: 2 [87680/96000 (91%)]\tLoss: 0.025976\n",
      "Train Epoch: 2 [88000/96000 (92%)]\tLoss: 0.001959\n",
      "Train Epoch: 2 [88320/96000 (92%)]\tLoss: 0.002157\n",
      "Train Epoch: 2 [88640/96000 (92%)]\tLoss: 0.118379\n",
      "Train Epoch: 2 [88960/96000 (93%)]\tLoss: 0.007001\n",
      "Train Epoch: 2 [89280/96000 (93%)]\tLoss: 0.003477\n",
      "Train Epoch: 2 [89600/96000 (93%)]\tLoss: 0.039535\n",
      "Train Epoch: 2 [89920/96000 (94%)]\tLoss: 0.002395\n",
      "Train Epoch: 2 [90240/96000 (94%)]\tLoss: 0.004584\n",
      "Train Epoch: 2 [90560/96000 (94%)]\tLoss: 0.001852\n",
      "Train Epoch: 2 [90880/96000 (95%)]\tLoss: 0.221245\n",
      "Train Epoch: 2 [91200/96000 (95%)]\tLoss: 0.013675\n",
      "Train Epoch: 2 [91520/96000 (95%)]\tLoss: 0.007333\n",
      "Train Epoch: 2 [91840/96000 (96%)]\tLoss: 0.000477\n",
      "Train Epoch: 2 [92160/96000 (96%)]\tLoss: 0.000870\n",
      "Train Epoch: 2 [92480/96000 (96%)]\tLoss: 0.005869\n",
      "Train Epoch: 2 [92800/96000 (97%)]\tLoss: 0.055790\n",
      "Train Epoch: 2 [93120/96000 (97%)]\tLoss: 0.002295\n",
      "Train Epoch: 2 [93440/96000 (97%)]\tLoss: 0.006797\n",
      "Train Epoch: 2 [93760/96000 (98%)]\tLoss: 0.135810\n",
      "Train Epoch: 2 [94080/96000 (98%)]\tLoss: 0.001517\n",
      "Train Epoch: 2 [94400/96000 (98%)]\tLoss: 0.015573\n",
      "Train Epoch: 2 [94720/96000 (99%)]\tLoss: 0.037688\n",
      "Train Epoch: 2 [95040/96000 (99%)]\tLoss: 0.010354\n",
      "Train Epoch: 2 [95360/96000 (99%)]\tLoss: 0.097442\n",
      "Train Epoch: 2 [95680/96000 (100%)]\tLoss: 0.134202\n",
      "\n",
      "Test set: Average loss: 0.0654, Accuracy: 3927/4000 (98.000%)\n",
      "\n",
      "Train Epoch: 3 [0/96000 (0%)]\tLoss: 0.001500\n",
      "Train Epoch: 3 [320/96000 (0%)]\tLoss: 0.000695\n",
      "Train Epoch: 3 [640/96000 (1%)]\tLoss: 0.009065\n",
      "Train Epoch: 3 [960/96000 (1%)]\tLoss: 0.007169\n",
      "Train Epoch: 3 [1280/96000 (1%)]\tLoss: 0.006925\n",
      "Train Epoch: 3 [1600/96000 (2%)]\tLoss: 0.029796\n",
      "Train Epoch: 3 [1920/96000 (2%)]\tLoss: 0.000667\n",
      "Train Epoch: 3 [2240/96000 (2%)]\tLoss: 0.002467\n",
      "Train Epoch: 3 [2560/96000 (3%)]\tLoss: 0.001414\n",
      "Train Epoch: 3 [2880/96000 (3%)]\tLoss: 0.000866\n",
      "Train Epoch: 3 [3200/96000 (3%)]\tLoss: 0.009305\n",
      "Train Epoch: 3 [3520/96000 (4%)]\tLoss: 0.001279\n",
      "Train Epoch: 3 [3840/96000 (4%)]\tLoss: 0.003035\n",
      "Train Epoch: 3 [4160/96000 (4%)]\tLoss: 0.001976\n",
      "Train Epoch: 3 [4480/96000 (5%)]\tLoss: 0.022846\n",
      "Train Epoch: 3 [4800/96000 (5%)]\tLoss: 0.066454\n",
      "Train Epoch: 3 [5120/96000 (5%)]\tLoss: 0.004300\n",
      "Train Epoch: 3 [5440/96000 (6%)]\tLoss: 0.002241\n",
      "Train Epoch: 3 [5760/96000 (6%)]\tLoss: 0.012266\n",
      "Train Epoch: 3 [6080/96000 (6%)]\tLoss: 0.004464\n",
      "Train Epoch: 3 [6400/96000 (7%)]\tLoss: 0.009761\n",
      "Train Epoch: 3 [6720/96000 (7%)]\tLoss: 0.048751\n",
      "Train Epoch: 3 [7040/96000 (7%)]\tLoss: 0.043879\n",
      "Train Epoch: 3 [7360/96000 (8%)]\tLoss: 0.002976\n",
      "Train Epoch: 3 [7680/96000 (8%)]\tLoss: 0.040890\n",
      "Train Epoch: 3 [8000/96000 (8%)]\tLoss: 0.000558\n",
      "Train Epoch: 3 [8320/96000 (9%)]\tLoss: 0.017372\n",
      "Train Epoch: 3 [8640/96000 (9%)]\tLoss: 0.001940\n",
      "Train Epoch: 3 [8960/96000 (9%)]\tLoss: 0.056244\n",
      "Train Epoch: 3 [9280/96000 (10%)]\tLoss: 0.006063\n",
      "Train Epoch: 3 [9600/96000 (10%)]\tLoss: 0.087572\n",
      "Train Epoch: 3 [9920/96000 (10%)]\tLoss: 0.008481\n",
      "Train Epoch: 3 [10240/96000 (11%)]\tLoss: 0.002017\n",
      "Train Epoch: 3 [10560/96000 (11%)]\tLoss: 0.005679\n",
      "Train Epoch: 3 [10880/96000 (11%)]\tLoss: 0.002319\n",
      "Train Epoch: 3 [11200/96000 (12%)]\tLoss: 0.000394\n",
      "Train Epoch: 3 [11520/96000 (12%)]\tLoss: 0.003858\n",
      "Train Epoch: 3 [11840/96000 (12%)]\tLoss: 0.016793\n",
      "Train Epoch: 3 [12160/96000 (13%)]\tLoss: 0.001118\n",
      "Train Epoch: 3 [12480/96000 (13%)]\tLoss: 0.004286\n",
      "Train Epoch: 3 [12800/96000 (13%)]\tLoss: 0.081576\n",
      "Train Epoch: 3 [13120/96000 (14%)]\tLoss: 0.013131\n",
      "Train Epoch: 3 [13440/96000 (14%)]\tLoss: 0.001543\n",
      "Train Epoch: 3 [13760/96000 (14%)]\tLoss: 0.002978\n",
      "Train Epoch: 3 [14080/96000 (15%)]\tLoss: 0.044959\n",
      "Train Epoch: 3 [14400/96000 (15%)]\tLoss: 0.000908\n",
      "Train Epoch: 3 [14720/96000 (15%)]\tLoss: 0.001349\n",
      "Train Epoch: 3 [15040/96000 (16%)]\tLoss: 0.021431\n",
      "Train Epoch: 3 [15360/96000 (16%)]\tLoss: 0.012761\n",
      "Train Epoch: 3 [15680/96000 (16%)]\tLoss: 0.003034\n",
      "Train Epoch: 3 [16000/96000 (17%)]\tLoss: 0.037154\n",
      "Train Epoch: 3 [16320/96000 (17%)]\tLoss: 0.000705\n",
      "Train Epoch: 3 [16640/96000 (17%)]\tLoss: 0.005452\n",
      "Train Epoch: 3 [16960/96000 (18%)]\tLoss: 0.012721\n",
      "Train Epoch: 3 [17280/96000 (18%)]\tLoss: 0.000394\n",
      "Train Epoch: 3 [17600/96000 (18%)]\tLoss: 0.086087\n",
      "Train Epoch: 3 [17920/96000 (19%)]\tLoss: 0.003638\n",
      "Train Epoch: 3 [18240/96000 (19%)]\tLoss: 0.015204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [18560/96000 (19%)]\tLoss: 0.001990\n",
      "Train Epoch: 3 [18880/96000 (20%)]\tLoss: 0.012256\n",
      "Train Epoch: 3 [19200/96000 (20%)]\tLoss: 0.045095\n",
      "Train Epoch: 3 [19520/96000 (20%)]\tLoss: 0.000653\n",
      "Train Epoch: 3 [19840/96000 (21%)]\tLoss: 0.223765\n",
      "Train Epoch: 3 [20160/96000 (21%)]\tLoss: 0.067364\n",
      "Train Epoch: 3 [20480/96000 (21%)]\tLoss: 0.027199\n",
      "Train Epoch: 3 [20800/96000 (22%)]\tLoss: 0.000265\n",
      "Train Epoch: 3 [21120/96000 (22%)]\tLoss: 0.005569\n",
      "Train Epoch: 3 [21440/96000 (22%)]\tLoss: 0.001512\n",
      "Train Epoch: 3 [21760/96000 (23%)]\tLoss: 0.000372\n",
      "Train Epoch: 3 [22080/96000 (23%)]\tLoss: 0.002037\n",
      "Train Epoch: 3 [22400/96000 (23%)]\tLoss: 0.088216\n",
      "Train Epoch: 3 [22720/96000 (24%)]\tLoss: 0.005728\n",
      "Train Epoch: 3 [23040/96000 (24%)]\tLoss: 0.010538\n",
      "Train Epoch: 3 [23360/96000 (24%)]\tLoss: 0.005958\n",
      "Train Epoch: 3 [23680/96000 (25%)]\tLoss: 0.000788\n",
      "Train Epoch: 3 [24000/96000 (25%)]\tLoss: 0.074605\n",
      "Train Epoch: 3 [24320/96000 (25%)]\tLoss: 0.065294\n",
      "Train Epoch: 3 [24640/96000 (26%)]\tLoss: 0.001283\n",
      "Train Epoch: 3 [24960/96000 (26%)]\tLoss: 0.000854\n",
      "Train Epoch: 3 [25280/96000 (26%)]\tLoss: 0.045396\n",
      "Train Epoch: 3 [25600/96000 (27%)]\tLoss: 0.001481\n",
      "Train Epoch: 3 [25920/96000 (27%)]\tLoss: 0.003402\n",
      "Train Epoch: 3 [26240/96000 (27%)]\tLoss: 0.011177\n",
      "Train Epoch: 3 [26560/96000 (28%)]\tLoss: 0.001047\n",
      "Train Epoch: 3 [26880/96000 (28%)]\tLoss: 0.000923\n",
      "Train Epoch: 3 [27200/96000 (28%)]\tLoss: 0.006879\n",
      "Train Epoch: 3 [27520/96000 (29%)]\tLoss: 0.056198\n",
      "Train Epoch: 3 [27840/96000 (29%)]\tLoss: 0.091390\n",
      "Train Epoch: 3 [28160/96000 (29%)]\tLoss: 0.000501\n",
      "Train Epoch: 3 [28480/96000 (30%)]\tLoss: 0.015057\n",
      "Train Epoch: 3 [28800/96000 (30%)]\tLoss: 0.002706\n",
      "Train Epoch: 3 [29120/96000 (30%)]\tLoss: 0.019633\n",
      "Train Epoch: 3 [29440/96000 (31%)]\tLoss: 0.065076\n",
      "Train Epoch: 3 [29760/96000 (31%)]\tLoss: 0.029454\n",
      "Train Epoch: 3 [30080/96000 (31%)]\tLoss: 0.015801\n",
      "Train Epoch: 3 [30400/96000 (32%)]\tLoss: 0.035867\n",
      "Train Epoch: 3 [30720/96000 (32%)]\tLoss: 0.005650\n",
      "Train Epoch: 3 [31040/96000 (32%)]\tLoss: 0.001459\n",
      "Train Epoch: 3 [31360/96000 (33%)]\tLoss: 0.017931\n",
      "Train Epoch: 3 [31680/96000 (33%)]\tLoss: 0.003025\n",
      "Train Epoch: 3 [32000/96000 (33%)]\tLoss: 0.002257\n",
      "Train Epoch: 3 [32320/96000 (34%)]\tLoss: 0.004868\n",
      "Train Epoch: 3 [32640/96000 (34%)]\tLoss: 0.283828\n",
      "Train Epoch: 3 [32960/96000 (34%)]\tLoss: 0.000934\n",
      "Train Epoch: 3 [33280/96000 (35%)]\tLoss: 0.009646\n",
      "Train Epoch: 3 [33600/96000 (35%)]\tLoss: 0.015300\n",
      "Train Epoch: 3 [33920/96000 (35%)]\tLoss: 0.031067\n",
      "Train Epoch: 3 [34240/96000 (36%)]\tLoss: 0.003255\n",
      "Train Epoch: 3 [34560/96000 (36%)]\tLoss: 0.000630\n",
      "Train Epoch: 3 [34880/96000 (36%)]\tLoss: 0.001942\n",
      "Train Epoch: 3 [35200/96000 (37%)]\tLoss: 0.015178\n",
      "Train Epoch: 3 [35520/96000 (37%)]\tLoss: 0.000876\n",
      "Train Epoch: 3 [35840/96000 (37%)]\tLoss: 0.002339\n",
      "Train Epoch: 3 [36160/96000 (38%)]\tLoss: 0.004423\n",
      "Train Epoch: 3 [36480/96000 (38%)]\tLoss: 0.008129\n",
      "Train Epoch: 3 [36800/96000 (38%)]\tLoss: 0.010088\n",
      "Train Epoch: 3 [37120/96000 (39%)]\tLoss: 0.162780\n",
      "Train Epoch: 3 [37440/96000 (39%)]\tLoss: 0.000745\n",
      "Train Epoch: 3 [37760/96000 (39%)]\tLoss: 0.039868\n",
      "Train Epoch: 3 [38080/96000 (40%)]\tLoss: 0.019455\n",
      "Train Epoch: 3 [38400/96000 (40%)]\tLoss: 0.000455\n",
      "Train Epoch: 3 [38720/96000 (40%)]\tLoss: 0.002034\n",
      "Train Epoch: 3 [39040/96000 (41%)]\tLoss: 0.011055\n",
      "Train Epoch: 3 [39360/96000 (41%)]\tLoss: 0.000705\n",
      "Train Epoch: 3 [39680/96000 (41%)]\tLoss: 0.108197\n",
      "Train Epoch: 3 [40000/96000 (42%)]\tLoss: 0.011672\n",
      "Train Epoch: 3 [40320/96000 (42%)]\tLoss: 0.000544\n",
      "Train Epoch: 3 [40640/96000 (42%)]\tLoss: 0.206471\n",
      "Train Epoch: 3 [40960/96000 (43%)]\tLoss: 0.001331\n",
      "Train Epoch: 3 [41280/96000 (43%)]\tLoss: 0.000567\n",
      "Train Epoch: 3 [41600/96000 (43%)]\tLoss: 0.000860\n",
      "Train Epoch: 3 [41920/96000 (44%)]\tLoss: 0.008581\n",
      "Train Epoch: 3 [42240/96000 (44%)]\tLoss: 0.001137\n",
      "Train Epoch: 3 [42560/96000 (44%)]\tLoss: 0.003151\n",
      "Train Epoch: 3 [42880/96000 (45%)]\tLoss: 0.004758\n",
      "Train Epoch: 3 [43200/96000 (45%)]\tLoss: 0.004718\n",
      "Train Epoch: 3 [43520/96000 (45%)]\tLoss: 0.142294\n",
      "Train Epoch: 3 [43840/96000 (46%)]\tLoss: 0.029506\n",
      "Train Epoch: 3 [44160/96000 (46%)]\tLoss: 0.003668\n",
      "Train Epoch: 3 [44480/96000 (46%)]\tLoss: 0.002680\n",
      "Train Epoch: 3 [44800/96000 (47%)]\tLoss: 0.002969\n",
      "Train Epoch: 3 [45120/96000 (47%)]\tLoss: 0.033927\n",
      "Train Epoch: 3 [45440/96000 (47%)]\tLoss: 0.009076\n",
      "Train Epoch: 3 [45760/96000 (48%)]\tLoss: 0.005088\n",
      "Train Epoch: 3 [46080/96000 (48%)]\tLoss: 0.003673\n",
      "Train Epoch: 3 [46400/96000 (48%)]\tLoss: 0.001446\n",
      "Train Epoch: 3 [46720/96000 (49%)]\tLoss: 0.002216\n",
      "Train Epoch: 3 [47040/96000 (49%)]\tLoss: 0.002704\n",
      "Train Epoch: 3 [47360/96000 (49%)]\tLoss: 0.004080\n",
      "Train Epoch: 3 [47680/96000 (50%)]\tLoss: 0.028501\n",
      "Train Epoch: 3 [48000/96000 (50%)]\tLoss: 0.008308\n",
      "Train Epoch: 3 [48320/96000 (50%)]\tLoss: 0.000682\n",
      "Train Epoch: 3 [48640/96000 (51%)]\tLoss: 0.016571\n",
      "Train Epoch: 3 [48960/96000 (51%)]\tLoss: 0.001481\n",
      "Train Epoch: 3 [49280/96000 (51%)]\tLoss: 0.000433\n",
      "Train Epoch: 3 [49600/96000 (52%)]\tLoss: 0.007709\n",
      "Train Epoch: 3 [49920/96000 (52%)]\tLoss: 0.019085\n",
      "Train Epoch: 3 [50240/96000 (52%)]\tLoss: 0.006731\n",
      "Train Epoch: 3 [50560/96000 (53%)]\tLoss: 0.033918\n",
      "Train Epoch: 3 [50880/96000 (53%)]\tLoss: 0.004379\n",
      "Train Epoch: 3 [51200/96000 (53%)]\tLoss: 0.015393\n",
      "Train Epoch: 3 [51520/96000 (54%)]\tLoss: 0.004311\n",
      "Train Epoch: 3 [51840/96000 (54%)]\tLoss: 0.000573\n",
      "Train Epoch: 3 [52160/96000 (54%)]\tLoss: 0.043293\n",
      "Train Epoch: 3 [52480/96000 (55%)]\tLoss: 0.027709\n",
      "Train Epoch: 3 [52800/96000 (55%)]\tLoss: 0.005804\n",
      "Train Epoch: 3 [53120/96000 (55%)]\tLoss: 0.005007\n",
      "Train Epoch: 3 [53440/96000 (56%)]\tLoss: 0.001121\n",
      "Train Epoch: 3 [53760/96000 (56%)]\tLoss: 0.000811\n",
      "Train Epoch: 3 [54080/96000 (56%)]\tLoss: 0.080284\n",
      "Train Epoch: 3 [54400/96000 (57%)]\tLoss: 0.007089\n",
      "Train Epoch: 3 [54720/96000 (57%)]\tLoss: 0.184921\n",
      "Train Epoch: 3 [55040/96000 (57%)]\tLoss: 0.001365\n",
      "Train Epoch: 3 [55360/96000 (58%)]\tLoss: 0.004732\n",
      "Train Epoch: 3 [55680/96000 (58%)]\tLoss: 0.014877\n",
      "Train Epoch: 3 [56000/96000 (58%)]\tLoss: 0.006271\n",
      "Train Epoch: 3 [56320/96000 (59%)]\tLoss: 0.091825\n",
      "Train Epoch: 3 [56640/96000 (59%)]\tLoss: 0.006094\n",
      "Train Epoch: 3 [56960/96000 (59%)]\tLoss: 0.001609\n",
      "Train Epoch: 3 [57280/96000 (60%)]\tLoss: 0.004011\n",
      "Train Epoch: 3 [57600/96000 (60%)]\tLoss: 0.027644\n",
      "Train Epoch: 3 [57920/96000 (60%)]\tLoss: 0.027271\n",
      "Train Epoch: 3 [58240/96000 (61%)]\tLoss: 0.007903\n",
      "Train Epoch: 3 [58560/96000 (61%)]\tLoss: 0.000967\n",
      "Train Epoch: 3 [58880/96000 (61%)]\tLoss: 0.002826\n",
      "Train Epoch: 3 [59200/96000 (62%)]\tLoss: 0.003796\n",
      "Train Epoch: 3 [59520/96000 (62%)]\tLoss: 0.040353\n",
      "Train Epoch: 3 [59840/96000 (62%)]\tLoss: 0.000845\n",
      "Train Epoch: 3 [60160/96000 (63%)]\tLoss: 0.016097\n",
      "Train Epoch: 3 [60480/96000 (63%)]\tLoss: 0.000942\n",
      "Train Epoch: 3 [60800/96000 (63%)]\tLoss: 0.000998\n",
      "Train Epoch: 3 [61120/96000 (64%)]\tLoss: 0.016718\n",
      "Train Epoch: 3 [61440/96000 (64%)]\tLoss: 0.005627\n",
      "Train Epoch: 3 [61760/96000 (64%)]\tLoss: 0.032728\n",
      "Train Epoch: 3 [62080/96000 (65%)]\tLoss: 0.022507\n",
      "Train Epoch: 3 [62400/96000 (65%)]\tLoss: 0.014080\n",
      "Train Epoch: 3 [62720/96000 (65%)]\tLoss: 0.004182\n",
      "Train Epoch: 3 [63040/96000 (66%)]\tLoss: 0.015142\n",
      "Train Epoch: 3 [63360/96000 (66%)]\tLoss: 0.005325\n",
      "Train Epoch: 3 [63680/96000 (66%)]\tLoss: 0.001990\n",
      "Train Epoch: 3 [64000/96000 (67%)]\tLoss: 0.001273\n",
      "Train Epoch: 3 [64320/96000 (67%)]\tLoss: 0.001574\n",
      "Train Epoch: 3 [64640/96000 (67%)]\tLoss: 0.007219\n",
      "Train Epoch: 3 [64960/96000 (68%)]\tLoss: 0.000832\n",
      "Train Epoch: 3 [65280/96000 (68%)]\tLoss: 0.001330\n",
      "Train Epoch: 3 [65600/96000 (68%)]\tLoss: 0.003715\n",
      "Train Epoch: 3 [65920/96000 (69%)]\tLoss: 0.000855\n",
      "Train Epoch: 3 [66240/96000 (69%)]\tLoss: 0.003273\n",
      "Train Epoch: 3 [66560/96000 (69%)]\tLoss: 0.000908\n",
      "Train Epoch: 3 [66880/96000 (70%)]\tLoss: 0.112599\n",
      "Train Epoch: 3 [67200/96000 (70%)]\tLoss: 0.000651\n",
      "Train Epoch: 3 [67520/96000 (70%)]\tLoss: 0.001457\n",
      "Train Epoch: 3 [67840/96000 (71%)]\tLoss: 0.004607\n",
      "Train Epoch: 3 [68160/96000 (71%)]\tLoss: 0.001518\n",
      "Train Epoch: 3 [68480/96000 (71%)]\tLoss: 0.041936\n",
      "Train Epoch: 3 [68800/96000 (72%)]\tLoss: 0.084626\n",
      "Train Epoch: 3 [69120/96000 (72%)]\tLoss: 0.026357\n",
      "Train Epoch: 3 [69440/96000 (72%)]\tLoss: 0.006997\n",
      "Train Epoch: 3 [69760/96000 (73%)]\tLoss: 0.001278\n",
      "Train Epoch: 3 [70080/96000 (73%)]\tLoss: 0.001827\n",
      "Train Epoch: 3 [70400/96000 (73%)]\tLoss: 0.002186\n",
      "Train Epoch: 3 [70720/96000 (74%)]\tLoss: 0.002663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 3 [71040/96000 (74%)]\tLoss: 0.005309\n",
      "Train Epoch: 3 [71360/96000 (74%)]\tLoss: 0.000635\n",
      "Train Epoch: 3 [71680/96000 (75%)]\tLoss: 0.000689\n",
      "Train Epoch: 3 [72000/96000 (75%)]\tLoss: 0.000471\n",
      "Train Epoch: 3 [72320/96000 (75%)]\tLoss: 0.001151\n",
      "Train Epoch: 3 [72640/96000 (76%)]\tLoss: 0.001693\n",
      "Train Epoch: 3 [72960/96000 (76%)]\tLoss: 0.000434\n",
      "Train Epoch: 3 [73280/96000 (76%)]\tLoss: 0.003231\n",
      "Train Epoch: 3 [73600/96000 (77%)]\tLoss: 0.067594\n",
      "Train Epoch: 3 [73920/96000 (77%)]\tLoss: 0.117314\n",
      "Train Epoch: 3 [74240/96000 (77%)]\tLoss: 0.008854\n",
      "Train Epoch: 3 [74560/96000 (78%)]\tLoss: 0.000852\n",
      "Train Epoch: 3 [74880/96000 (78%)]\tLoss: 0.003798\n",
      "Train Epoch: 3 [75200/96000 (78%)]\tLoss: 0.030412\n",
      "Train Epoch: 3 [75520/96000 (79%)]\tLoss: 0.000848\n",
      "Train Epoch: 3 [75840/96000 (79%)]\tLoss: 0.052086\n",
      "Train Epoch: 3 [76160/96000 (79%)]\tLoss: 0.049043\n",
      "Train Epoch: 3 [76480/96000 (80%)]\tLoss: 0.038297\n",
      "Train Epoch: 3 [76800/96000 (80%)]\tLoss: 0.001103\n",
      "Train Epoch: 3 [77120/96000 (80%)]\tLoss: 0.000341\n",
      "Train Epoch: 3 [77440/96000 (81%)]\tLoss: 0.000879\n",
      "Train Epoch: 3 [77760/96000 (81%)]\tLoss: 0.000441\n",
      "Train Epoch: 3 [78080/96000 (81%)]\tLoss: 0.133990\n",
      "Train Epoch: 3 [78400/96000 (82%)]\tLoss: 0.005346\n",
      "Train Epoch: 3 [78720/96000 (82%)]\tLoss: 0.101551\n",
      "Train Epoch: 3 [79040/96000 (82%)]\tLoss: 0.008199\n",
      "Train Epoch: 3 [79360/96000 (83%)]\tLoss: 0.001023\n",
      "Train Epoch: 3 [79680/96000 (83%)]\tLoss: 0.003668\n",
      "Train Epoch: 3 [80000/96000 (83%)]\tLoss: 0.000715\n",
      "Train Epoch: 3 [80320/96000 (84%)]\tLoss: 0.013339\n",
      "Train Epoch: 3 [80640/96000 (84%)]\tLoss: 0.009645\n",
      "Train Epoch: 3 [80960/96000 (84%)]\tLoss: 0.000193\n",
      "Train Epoch: 3 [81280/96000 (85%)]\tLoss: 0.008205\n",
      "Train Epoch: 3 [81600/96000 (85%)]\tLoss: 0.001223\n",
      "Train Epoch: 3 [81920/96000 (85%)]\tLoss: 0.001707\n",
      "Train Epoch: 3 [82240/96000 (86%)]\tLoss: 0.000477\n",
      "Train Epoch: 3 [82560/96000 (86%)]\tLoss: 0.032474\n",
      "Train Epoch: 3 [82880/96000 (86%)]\tLoss: 0.023755\n",
      "Train Epoch: 3 [83200/96000 (87%)]\tLoss: 0.051036\n",
      "Train Epoch: 3 [83520/96000 (87%)]\tLoss: 0.002597\n",
      "Train Epoch: 3 [83840/96000 (87%)]\tLoss: 0.145676\n",
      "Train Epoch: 3 [84160/96000 (88%)]\tLoss: 0.000623\n",
      "Train Epoch: 3 [84480/96000 (88%)]\tLoss: 0.001350\n",
      "Train Epoch: 3 [84800/96000 (88%)]\tLoss: 0.054518\n",
      "Train Epoch: 3 [85120/96000 (89%)]\tLoss: 0.007680\n",
      "Train Epoch: 3 [85440/96000 (89%)]\tLoss: 0.019918\n",
      "Train Epoch: 3 [85760/96000 (89%)]\tLoss: 0.006070\n",
      "Train Epoch: 3 [86080/96000 (90%)]\tLoss: 0.002577\n",
      "Train Epoch: 3 [86400/96000 (90%)]\tLoss: 0.157664\n",
      "Train Epoch: 3 [86720/96000 (90%)]\tLoss: 0.090500\n",
      "Train Epoch: 3 [87040/96000 (91%)]\tLoss: 0.007147\n",
      "Train Epoch: 3 [87360/96000 (91%)]\tLoss: 0.040289\n",
      "Train Epoch: 3 [87680/96000 (91%)]\tLoss: 0.187991\n",
      "Train Epoch: 3 [88000/96000 (92%)]\tLoss: 0.003632\n",
      "Train Epoch: 3 [88320/96000 (92%)]\tLoss: 0.021485\n",
      "Train Epoch: 3 [88640/96000 (92%)]\tLoss: 0.002573\n",
      "Train Epoch: 3 [88960/96000 (93%)]\tLoss: 0.003067\n",
      "Train Epoch: 3 [89280/96000 (93%)]\tLoss: 0.000283\n",
      "Train Epoch: 3 [89600/96000 (93%)]\tLoss: 0.000345\n",
      "Train Epoch: 3 [89920/96000 (94%)]\tLoss: 0.271249\n",
      "Train Epoch: 3 [90240/96000 (94%)]\tLoss: 0.010445\n",
      "Train Epoch: 3 [90560/96000 (94%)]\tLoss: 0.000500\n",
      "Train Epoch: 3 [90880/96000 (95%)]\tLoss: 0.001188\n",
      "Train Epoch: 3 [91200/96000 (95%)]\tLoss: 0.005111\n",
      "Train Epoch: 3 [91520/96000 (95%)]\tLoss: 0.065595\n",
      "Train Epoch: 3 [91840/96000 (96%)]\tLoss: 0.003051\n",
      "Train Epoch: 3 [92160/96000 (96%)]\tLoss: 0.000291\n",
      "Train Epoch: 3 [92480/96000 (96%)]\tLoss: 0.005656\n",
      "Train Epoch: 3 [92800/96000 (97%)]\tLoss: 0.000627\n",
      "Train Epoch: 3 [93120/96000 (97%)]\tLoss: 0.000367\n",
      "Train Epoch: 3 [93440/96000 (97%)]\tLoss: 0.009542\n",
      "Train Epoch: 3 [93760/96000 (98%)]\tLoss: 0.010370\n",
      "Train Epoch: 3 [94080/96000 (98%)]\tLoss: 0.024202\n",
      "Train Epoch: 3 [94400/96000 (98%)]\tLoss: 0.222648\n",
      "Train Epoch: 3 [94720/96000 (99%)]\tLoss: 0.000274\n",
      "Train Epoch: 3 [95040/96000 (99%)]\tLoss: 0.005805\n",
      "Train Epoch: 3 [95360/96000 (99%)]\tLoss: 0.003192\n",
      "Train Epoch: 3 [95680/96000 (100%)]\tLoss: 0.009688\n",
      "\n",
      "Test set: Average loss: 0.0642, Accuracy: 3926/4000 (98.000%)\n",
      "\n",
      "Train Epoch: 4 [0/96000 (0%)]\tLoss: 0.008485\n",
      "Train Epoch: 4 [320/96000 (0%)]\tLoss: 0.001058\n",
      "Train Epoch: 4 [640/96000 (1%)]\tLoss: 0.002959\n",
      "Train Epoch: 4 [960/96000 (1%)]\tLoss: 0.126476\n",
      "Train Epoch: 4 [1280/96000 (1%)]\tLoss: 0.000691\n",
      "Train Epoch: 4 [1600/96000 (2%)]\tLoss: 0.027200\n",
      "Train Epoch: 4 [1920/96000 (2%)]\tLoss: 0.000572\n",
      "Train Epoch: 4 [2240/96000 (2%)]\tLoss: 0.000384\n",
      "Train Epoch: 4 [2560/96000 (3%)]\tLoss: 0.002212\n",
      "Train Epoch: 4 [2880/96000 (3%)]\tLoss: 0.000677\n",
      "Train Epoch: 4 [3200/96000 (3%)]\tLoss: 0.003093\n",
      "Train Epoch: 4 [3520/96000 (4%)]\tLoss: 0.125477\n",
      "Train Epoch: 4 [3840/96000 (4%)]\tLoss: 0.004178\n",
      "Train Epoch: 4 [4160/96000 (4%)]\tLoss: 0.000641\n",
      "Train Epoch: 4 [4480/96000 (5%)]\tLoss: 0.008243\n",
      "Train Epoch: 4 [4800/96000 (5%)]\tLoss: 0.076145\n",
      "Train Epoch: 4 [5120/96000 (5%)]\tLoss: 0.018958\n",
      "Train Epoch: 4 [5440/96000 (6%)]\tLoss: 0.066224\n",
      "Train Epoch: 4 [5760/96000 (6%)]\tLoss: 0.187504\n",
      "Train Epoch: 4 [6080/96000 (6%)]\tLoss: 0.144892\n",
      "Train Epoch: 4 [6400/96000 (7%)]\tLoss: 0.150499\n",
      "Train Epoch: 4 [6720/96000 (7%)]\tLoss: 0.166912\n",
      "Train Epoch: 4 [7040/96000 (7%)]\tLoss: 0.011781\n",
      "Train Epoch: 4 [7360/96000 (8%)]\tLoss: 0.008620\n",
      "Train Epoch: 4 [7680/96000 (8%)]\tLoss: 0.000993\n",
      "Train Epoch: 4 [8000/96000 (8%)]\tLoss: 0.009899\n",
      "Train Epoch: 4 [8320/96000 (9%)]\tLoss: 0.001852\n",
      "Train Epoch: 4 [8640/96000 (9%)]\tLoss: 0.000968\n",
      "Train Epoch: 4 [8960/96000 (9%)]\tLoss: 0.001424\n",
      "Train Epoch: 4 [9280/96000 (10%)]\tLoss: 0.161070\n",
      "Train Epoch: 4 [9600/96000 (10%)]\tLoss: 0.002285\n",
      "Train Epoch: 4 [9920/96000 (10%)]\tLoss: 0.000459\n",
      "Train Epoch: 4 [10240/96000 (11%)]\tLoss: 0.005489\n",
      "Train Epoch: 4 [10560/96000 (11%)]\tLoss: 0.007824\n",
      "Train Epoch: 4 [10880/96000 (11%)]\tLoss: 0.007002\n",
      "Train Epoch: 4 [11200/96000 (12%)]\tLoss: 0.039026\n",
      "Train Epoch: 4 [11520/96000 (12%)]\tLoss: 0.002467\n",
      "Train Epoch: 4 [11840/96000 (12%)]\tLoss: 0.002495\n",
      "Train Epoch: 4 [12160/96000 (13%)]\tLoss: 0.063824\n",
      "Train Epoch: 4 [12480/96000 (13%)]\tLoss: 0.009880\n",
      "Train Epoch: 4 [12800/96000 (13%)]\tLoss: 0.002675\n",
      "Train Epoch: 4 [13120/96000 (14%)]\tLoss: 0.001126\n",
      "Train Epoch: 4 [13440/96000 (14%)]\tLoss: 0.001865\n",
      "Train Epoch: 4 [13760/96000 (14%)]\tLoss: 0.002506\n",
      "Train Epoch: 4 [14080/96000 (15%)]\tLoss: 0.000613\n",
      "Train Epoch: 4 [14400/96000 (15%)]\tLoss: 0.000879\n",
      "Train Epoch: 4 [14720/96000 (15%)]\tLoss: 0.000327\n",
      "Train Epoch: 4 [15040/96000 (16%)]\tLoss: 0.003275\n",
      "Train Epoch: 4 [15360/96000 (16%)]\tLoss: 0.001101\n",
      "Train Epoch: 4 [15680/96000 (16%)]\tLoss: 0.001732\n",
      "Train Epoch: 4 [16000/96000 (17%)]\tLoss: 0.024030\n",
      "Train Epoch: 4 [16320/96000 (17%)]\tLoss: 0.002047\n",
      "Train Epoch: 4 [16640/96000 (17%)]\tLoss: 0.002860\n",
      "Train Epoch: 4 [16960/96000 (18%)]\tLoss: 0.015061\n",
      "Train Epoch: 4 [17280/96000 (18%)]\tLoss: 0.000425\n",
      "Train Epoch: 4 [17600/96000 (18%)]\tLoss: 0.004568\n",
      "Train Epoch: 4 [17920/96000 (19%)]\tLoss: 0.010474\n",
      "Train Epoch: 4 [18240/96000 (19%)]\tLoss: 0.075354\n",
      "Train Epoch: 4 [18560/96000 (19%)]\tLoss: 0.001816\n",
      "Train Epoch: 4 [18880/96000 (20%)]\tLoss: 0.036491\n",
      "Train Epoch: 4 [19200/96000 (20%)]\tLoss: 0.023497\n",
      "Train Epoch: 4 [19520/96000 (20%)]\tLoss: 0.094101\n",
      "Train Epoch: 4 [19840/96000 (21%)]\tLoss: 0.014767\n",
      "Train Epoch: 4 [20160/96000 (21%)]\tLoss: 0.015938\n",
      "Train Epoch: 4 [20480/96000 (21%)]\tLoss: 0.022467\n",
      "Train Epoch: 4 [20800/96000 (22%)]\tLoss: 0.068677\n",
      "Train Epoch: 4 [21120/96000 (22%)]\tLoss: 0.001824\n",
      "Train Epoch: 4 [21440/96000 (22%)]\tLoss: 0.001585\n",
      "Train Epoch: 4 [21760/96000 (23%)]\tLoss: 0.000950\n",
      "Train Epoch: 4 [22080/96000 (23%)]\tLoss: 0.004125\n",
      "Train Epoch: 4 [22400/96000 (23%)]\tLoss: 0.197534\n",
      "Train Epoch: 4 [22720/96000 (24%)]\tLoss: 0.027251\n",
      "Train Epoch: 4 [23040/96000 (24%)]\tLoss: 0.005889\n",
      "Train Epoch: 4 [23360/96000 (24%)]\tLoss: 0.016071\n",
      "Train Epoch: 4 [23680/96000 (25%)]\tLoss: 0.004409\n",
      "Train Epoch: 4 [24000/96000 (25%)]\tLoss: 0.022344\n",
      "Train Epoch: 4 [24320/96000 (25%)]\tLoss: 0.001977\n",
      "Train Epoch: 4 [24640/96000 (26%)]\tLoss: 0.002267\n",
      "Train Epoch: 4 [24960/96000 (26%)]\tLoss: 0.001309\n",
      "Train Epoch: 4 [25280/96000 (26%)]\tLoss: 0.000365\n",
      "Train Epoch: 4 [25600/96000 (27%)]\tLoss: 0.000901\n",
      "Train Epoch: 4 [25920/96000 (27%)]\tLoss: 0.017664\n",
      "Train Epoch: 4 [26240/96000 (27%)]\tLoss: 0.001579\n",
      "Train Epoch: 4 [26560/96000 (28%)]\tLoss: 0.002715\n",
      "Train Epoch: 4 [26880/96000 (28%)]\tLoss: 0.000306\n",
      "Train Epoch: 4 [27200/96000 (28%)]\tLoss: 0.001125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [27520/96000 (29%)]\tLoss: 0.002570\n",
      "Train Epoch: 4 [27840/96000 (29%)]\tLoss: 0.013143\n",
      "Train Epoch: 4 [28160/96000 (29%)]\tLoss: 0.001115\n",
      "Train Epoch: 4 [28480/96000 (30%)]\tLoss: 0.016233\n",
      "Train Epoch: 4 [28800/96000 (30%)]\tLoss: 0.001755\n",
      "Train Epoch: 4 [29120/96000 (30%)]\tLoss: 0.006474\n",
      "Train Epoch: 4 [29440/96000 (31%)]\tLoss: 0.000923\n",
      "Train Epoch: 4 [29760/96000 (31%)]\tLoss: 0.000626\n",
      "Train Epoch: 4 [30080/96000 (31%)]\tLoss: 0.027072\n",
      "Train Epoch: 4 [30400/96000 (32%)]\tLoss: 0.002183\n",
      "Train Epoch: 4 [30720/96000 (32%)]\tLoss: 0.096204\n",
      "Train Epoch: 4 [31040/96000 (32%)]\tLoss: 0.002551\n",
      "Train Epoch: 4 [31360/96000 (33%)]\tLoss: 0.006418\n",
      "Train Epoch: 4 [31680/96000 (33%)]\tLoss: 0.002571\n",
      "Train Epoch: 4 [32000/96000 (33%)]\tLoss: 0.002297\n",
      "Train Epoch: 4 [32320/96000 (34%)]\tLoss: 0.027003\n",
      "Train Epoch: 4 [32640/96000 (34%)]\tLoss: 0.003520\n",
      "Train Epoch: 4 [32960/96000 (34%)]\tLoss: 0.040245\n",
      "Train Epoch: 4 [33280/96000 (35%)]\tLoss: 0.006282\n",
      "Train Epoch: 4 [33600/96000 (35%)]\tLoss: 0.003127\n",
      "Train Epoch: 4 [33920/96000 (35%)]\tLoss: 0.020016\n",
      "Train Epoch: 4 [34240/96000 (36%)]\tLoss: 0.004038\n",
      "Train Epoch: 4 [34560/96000 (36%)]\tLoss: 0.111368\n",
      "Train Epoch: 4 [34880/96000 (36%)]\tLoss: 0.003028\n",
      "Train Epoch: 4 [35200/96000 (37%)]\tLoss: 0.056186\n",
      "Train Epoch: 4 [35520/96000 (37%)]\tLoss: 0.002562\n",
      "Train Epoch: 4 [35840/96000 (37%)]\tLoss: 0.007446\n",
      "Train Epoch: 4 [36160/96000 (38%)]\tLoss: 0.001816\n",
      "Train Epoch: 4 [36480/96000 (38%)]\tLoss: 0.002478\n",
      "Train Epoch: 4 [36800/96000 (38%)]\tLoss: 0.006552\n",
      "Train Epoch: 4 [37120/96000 (39%)]\tLoss: 0.020749\n",
      "Train Epoch: 4 [37440/96000 (39%)]\tLoss: 0.001730\n",
      "Train Epoch: 4 [37760/96000 (39%)]\tLoss: 0.025985\n",
      "Train Epoch: 4 [38080/96000 (40%)]\tLoss: 0.004195\n",
      "Train Epoch: 4 [38400/96000 (40%)]\tLoss: 0.005220\n",
      "Train Epoch: 4 [38720/96000 (40%)]\tLoss: 0.019914\n",
      "Train Epoch: 4 [39040/96000 (41%)]\tLoss: 0.046879\n",
      "Train Epoch: 4 [39360/96000 (41%)]\tLoss: 0.005174\n",
      "Train Epoch: 4 [39680/96000 (41%)]\tLoss: 0.001381\n",
      "Train Epoch: 4 [40000/96000 (42%)]\tLoss: 0.016218\n",
      "Train Epoch: 4 [40320/96000 (42%)]\tLoss: 0.001562\n",
      "Train Epoch: 4 [40640/96000 (42%)]\tLoss: 0.001591\n",
      "Train Epoch: 4 [40960/96000 (43%)]\tLoss: 0.002239\n",
      "Train Epoch: 4 [41280/96000 (43%)]\tLoss: 0.001831\n",
      "Train Epoch: 4 [41600/96000 (43%)]\tLoss: 0.006449\n",
      "Train Epoch: 4 [41920/96000 (44%)]\tLoss: 0.001791\n",
      "Train Epoch: 4 [42240/96000 (44%)]\tLoss: 0.001756\n",
      "Train Epoch: 4 [42560/96000 (44%)]\tLoss: 0.002965\n",
      "Train Epoch: 4 [42880/96000 (45%)]\tLoss: 0.050777\n",
      "Train Epoch: 4 [43200/96000 (45%)]\tLoss: 0.004580\n",
      "Train Epoch: 4 [43520/96000 (45%)]\tLoss: 0.001958\n",
      "Train Epoch: 4 [43840/96000 (46%)]\tLoss: 0.000366\n",
      "Train Epoch: 4 [44160/96000 (46%)]\tLoss: 0.003882\n",
      "Train Epoch: 4 [44480/96000 (46%)]\tLoss: 0.002625\n",
      "Train Epoch: 4 [44800/96000 (47%)]\tLoss: 0.001320\n",
      "Train Epoch: 4 [45120/96000 (47%)]\tLoss: 0.014769\n",
      "Train Epoch: 4 [45440/96000 (47%)]\tLoss: 0.003498\n",
      "Train Epoch: 4 [45760/96000 (48%)]\tLoss: 0.021898\n",
      "Train Epoch: 4 [46080/96000 (48%)]\tLoss: 0.115647\n",
      "Train Epoch: 4 [46400/96000 (48%)]\tLoss: 0.001190\n",
      "Train Epoch: 4 [46720/96000 (49%)]\tLoss: 0.007265\n",
      "Train Epoch: 4 [47040/96000 (49%)]\tLoss: 0.003166\n",
      "Train Epoch: 4 [47360/96000 (49%)]\tLoss: 0.012935\n",
      "Train Epoch: 4 [47680/96000 (50%)]\tLoss: 0.000794\n",
      "Train Epoch: 4 [48000/96000 (50%)]\tLoss: 0.003920\n",
      "Train Epoch: 4 [48320/96000 (50%)]\tLoss: 0.007818\n",
      "Train Epoch: 4 [48640/96000 (51%)]\tLoss: 0.001551\n",
      "Train Epoch: 4 [48960/96000 (51%)]\tLoss: 0.002461\n",
      "Train Epoch: 4 [49280/96000 (51%)]\tLoss: 0.005502\n",
      "Train Epoch: 4 [49600/96000 (52%)]\tLoss: 0.003334\n",
      "Train Epoch: 4 [49920/96000 (52%)]\tLoss: 0.008275\n",
      "Train Epoch: 4 [50240/96000 (52%)]\tLoss: 0.000803\n",
      "Train Epoch: 4 [50560/96000 (53%)]\tLoss: 0.002136\n",
      "Train Epoch: 4 [50880/96000 (53%)]\tLoss: 0.003187\n",
      "Train Epoch: 4 [51200/96000 (53%)]\tLoss: 0.000670\n",
      "Train Epoch: 4 [51520/96000 (54%)]\tLoss: 0.000992\n",
      "Train Epoch: 4 [51840/96000 (54%)]\tLoss: 0.024614\n",
      "Train Epoch: 4 [52160/96000 (54%)]\tLoss: 0.000613\n",
      "Train Epoch: 4 [52480/96000 (55%)]\tLoss: 0.002448\n",
      "Train Epoch: 4 [52800/96000 (55%)]\tLoss: 0.000731\n",
      "Train Epoch: 4 [53120/96000 (55%)]\tLoss: 0.003610\n",
      "Train Epoch: 4 [53440/96000 (56%)]\tLoss: 0.000546\n",
      "Train Epoch: 4 [53760/96000 (56%)]\tLoss: 0.000511\n",
      "Train Epoch: 4 [54080/96000 (56%)]\tLoss: 0.019375\n",
      "Train Epoch: 4 [54400/96000 (57%)]\tLoss: 0.006240\n",
      "Train Epoch: 4 [54720/96000 (57%)]\tLoss: 0.008370\n",
      "Train Epoch: 4 [55040/96000 (57%)]\tLoss: 0.146151\n",
      "Train Epoch: 4 [55360/96000 (58%)]\tLoss: 0.010137\n",
      "Train Epoch: 4 [55680/96000 (58%)]\tLoss: 0.000503\n",
      "Train Epoch: 4 [56000/96000 (58%)]\tLoss: 0.001759\n",
      "Train Epoch: 4 [56320/96000 (59%)]\tLoss: 0.000515\n",
      "Train Epoch: 4 [56640/96000 (59%)]\tLoss: 0.086732\n",
      "Train Epoch: 4 [56960/96000 (59%)]\tLoss: 0.007593\n",
      "Train Epoch: 4 [57280/96000 (60%)]\tLoss: 0.001368\n",
      "Train Epoch: 4 [57600/96000 (60%)]\tLoss: 0.002621\n",
      "Train Epoch: 4 [57920/96000 (60%)]\tLoss: 0.001989\n",
      "Train Epoch: 4 [58240/96000 (61%)]\tLoss: 0.001205\n",
      "Train Epoch: 4 [58560/96000 (61%)]\tLoss: 0.005553\n",
      "Train Epoch: 4 [58880/96000 (61%)]\tLoss: 0.170105\n",
      "Train Epoch: 4 [59200/96000 (62%)]\tLoss: 0.000827\n",
      "Train Epoch: 4 [59520/96000 (62%)]\tLoss: 0.001472\n",
      "Train Epoch: 4 [59840/96000 (62%)]\tLoss: 0.002262\n",
      "Train Epoch: 4 [60160/96000 (63%)]\tLoss: 0.001039\n",
      "Train Epoch: 4 [60480/96000 (63%)]\tLoss: 0.001431\n",
      "Train Epoch: 4 [60800/96000 (63%)]\tLoss: 0.000284\n",
      "Train Epoch: 4 [61120/96000 (64%)]\tLoss: 0.005364\n",
      "Train Epoch: 4 [61440/96000 (64%)]\tLoss: 0.000892\n",
      "Train Epoch: 4 [61760/96000 (64%)]\tLoss: 0.001816\n",
      "Train Epoch: 4 [62080/96000 (65%)]\tLoss: 0.031493\n",
      "Train Epoch: 4 [62400/96000 (65%)]\tLoss: 0.023370\n",
      "Train Epoch: 4 [62720/96000 (65%)]\tLoss: 0.001555\n",
      "Train Epoch: 4 [63040/96000 (66%)]\tLoss: 0.009126\n",
      "Train Epoch: 4 [63360/96000 (66%)]\tLoss: 0.017869\n",
      "Train Epoch: 4 [63680/96000 (66%)]\tLoss: 0.001014\n",
      "Train Epoch: 4 [64000/96000 (67%)]\tLoss: 0.000937\n",
      "Train Epoch: 4 [64320/96000 (67%)]\tLoss: 0.132361\n",
      "Train Epoch: 4 [64640/96000 (67%)]\tLoss: 0.000861\n",
      "Train Epoch: 4 [64960/96000 (68%)]\tLoss: 0.000454\n",
      "Train Epoch: 4 [65280/96000 (68%)]\tLoss: 0.000363\n",
      "Train Epoch: 4 [65600/96000 (68%)]\tLoss: 0.004718\n",
      "Train Epoch: 4 [65920/96000 (69%)]\tLoss: 0.027749\n",
      "Train Epoch: 4 [66240/96000 (69%)]\tLoss: 0.015605\n",
      "Train Epoch: 4 [66560/96000 (69%)]\tLoss: 0.189776\n",
      "Train Epoch: 4 [66880/96000 (70%)]\tLoss: 0.003290\n",
      "Train Epoch: 4 [67200/96000 (70%)]\tLoss: 0.001452\n",
      "Train Epoch: 4 [67520/96000 (70%)]\tLoss: 0.015068\n",
      "Train Epoch: 4 [67840/96000 (71%)]\tLoss: 0.004741\n",
      "Train Epoch: 4 [68160/96000 (71%)]\tLoss: 0.002427\n",
      "Train Epoch: 4 [68480/96000 (71%)]\tLoss: 0.003713\n",
      "Train Epoch: 4 [68800/96000 (72%)]\tLoss: 0.009191\n",
      "Train Epoch: 4 [69120/96000 (72%)]\tLoss: 0.000997\n",
      "Train Epoch: 4 [69440/96000 (72%)]\tLoss: 0.001890\n",
      "Train Epoch: 4 [69760/96000 (73%)]\tLoss: 0.003740\n",
      "Train Epoch: 4 [70080/96000 (73%)]\tLoss: 0.083904\n",
      "Train Epoch: 4 [70400/96000 (73%)]\tLoss: 0.045601\n",
      "Train Epoch: 4 [70720/96000 (74%)]\tLoss: 0.001035\n",
      "Train Epoch: 4 [71040/96000 (74%)]\tLoss: 0.000784\n",
      "Train Epoch: 4 [71360/96000 (74%)]\tLoss: 0.000293\n",
      "Train Epoch: 4 [71680/96000 (75%)]\tLoss: 0.002416\n",
      "Train Epoch: 4 [72000/96000 (75%)]\tLoss: 0.000868\n",
      "Train Epoch: 4 [72320/96000 (75%)]\tLoss: 0.001831\n",
      "Train Epoch: 4 [72640/96000 (76%)]\tLoss: 0.001559\n",
      "Train Epoch: 4 [72960/96000 (76%)]\tLoss: 0.000548\n",
      "Train Epoch: 4 [73280/96000 (76%)]\tLoss: 0.010344\n",
      "Train Epoch: 4 [73600/96000 (77%)]\tLoss: 0.139108\n",
      "Train Epoch: 4 [73920/96000 (77%)]\tLoss: 0.005364\n",
      "Train Epoch: 4 [74240/96000 (77%)]\tLoss: 0.003046\n",
      "Train Epoch: 4 [74560/96000 (78%)]\tLoss: 0.003081\n",
      "Train Epoch: 4 [74880/96000 (78%)]\tLoss: 0.010686\n",
      "Train Epoch: 4 [75200/96000 (78%)]\tLoss: 0.003243\n",
      "Train Epoch: 4 [75520/96000 (79%)]\tLoss: 0.003571\n",
      "Train Epoch: 4 [75840/96000 (79%)]\tLoss: 0.001944\n",
      "Train Epoch: 4 [76160/96000 (79%)]\tLoss: 0.007618\n",
      "Train Epoch: 4 [76480/96000 (80%)]\tLoss: 0.000544\n",
      "Train Epoch: 4 [76800/96000 (80%)]\tLoss: 0.001799\n",
      "Train Epoch: 4 [77120/96000 (80%)]\tLoss: 0.000412\n",
      "Train Epoch: 4 [77440/96000 (81%)]\tLoss: 0.004266\n",
      "Train Epoch: 4 [77760/96000 (81%)]\tLoss: 0.004883\n",
      "Train Epoch: 4 [78080/96000 (81%)]\tLoss: 0.001013\n",
      "Train Epoch: 4 [78400/96000 (82%)]\tLoss: 0.002068\n",
      "Train Epoch: 4 [78720/96000 (82%)]\tLoss: 0.005593\n",
      "Train Epoch: 4 [79040/96000 (82%)]\tLoss: 0.008772\n",
      "Train Epoch: 4 [79360/96000 (83%)]\tLoss: 0.000332\n",
      "Train Epoch: 4 [79680/96000 (83%)]\tLoss: 0.007458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 4 [80000/96000 (83%)]\tLoss: 0.028478\n",
      "Train Epoch: 4 [80320/96000 (84%)]\tLoss: 0.030007\n",
      "Train Epoch: 4 [80640/96000 (84%)]\tLoss: 0.002144\n",
      "Train Epoch: 4 [80960/96000 (84%)]\tLoss: 0.003994\n",
      "Train Epoch: 4 [81280/96000 (85%)]\tLoss: 0.000253\n",
      "Train Epoch: 4 [81600/96000 (85%)]\tLoss: 0.000648\n",
      "Train Epoch: 4 [81920/96000 (85%)]\tLoss: 0.001753\n",
      "Train Epoch: 4 [82240/96000 (86%)]\tLoss: 0.000315\n",
      "Train Epoch: 4 [82560/96000 (86%)]\tLoss: 0.000514\n",
      "Train Epoch: 4 [82880/96000 (86%)]\tLoss: 0.028255\n",
      "Train Epoch: 4 [83200/96000 (87%)]\tLoss: 0.000859\n",
      "Train Epoch: 4 [83520/96000 (87%)]\tLoss: 0.000710\n",
      "Train Epoch: 4 [83840/96000 (87%)]\tLoss: 0.001220\n",
      "Train Epoch: 4 [84160/96000 (88%)]\tLoss: 0.000470\n",
      "Train Epoch: 4 [84480/96000 (88%)]\tLoss: 0.032698\n",
      "Train Epoch: 4 [84800/96000 (88%)]\tLoss: 0.001749\n",
      "Train Epoch: 4 [85120/96000 (89%)]\tLoss: 0.002832\n",
      "Train Epoch: 4 [85440/96000 (89%)]\tLoss: 0.007419\n",
      "Train Epoch: 4 [85760/96000 (89%)]\tLoss: 0.001654\n",
      "Train Epoch: 4 [86080/96000 (90%)]\tLoss: 0.002906\n",
      "Train Epoch: 4 [86400/96000 (90%)]\tLoss: 0.006145\n",
      "Train Epoch: 4 [86720/96000 (90%)]\tLoss: 0.025120\n",
      "Train Epoch: 4 [87040/96000 (91%)]\tLoss: 0.005914\n",
      "Train Epoch: 4 [87360/96000 (91%)]\tLoss: 0.012151\n",
      "Train Epoch: 4 [87680/96000 (91%)]\tLoss: 0.001096\n",
      "Train Epoch: 4 [88000/96000 (92%)]\tLoss: 0.352526\n",
      "Train Epoch: 4 [88320/96000 (92%)]\tLoss: 0.011644\n",
      "Train Epoch: 4 [88640/96000 (92%)]\tLoss: 0.000504\n",
      "Train Epoch: 4 [88960/96000 (93%)]\tLoss: 0.021465\n",
      "Train Epoch: 4 [89280/96000 (93%)]\tLoss: 0.008031\n",
      "Train Epoch: 4 [89600/96000 (93%)]\tLoss: 0.000478\n",
      "Train Epoch: 4 [89920/96000 (94%)]\tLoss: 0.000837\n",
      "Train Epoch: 4 [90240/96000 (94%)]\tLoss: 0.001438\n",
      "Train Epoch: 4 [90560/96000 (94%)]\tLoss: 0.001918\n",
      "Train Epoch: 4 [90880/96000 (95%)]\tLoss: 0.006506\n",
      "Train Epoch: 4 [91200/96000 (95%)]\tLoss: 0.001556\n",
      "Train Epoch: 4 [91520/96000 (95%)]\tLoss: 0.003677\n",
      "Train Epoch: 4 [91840/96000 (96%)]\tLoss: 0.003456\n",
      "Train Epoch: 4 [92160/96000 (96%)]\tLoss: 0.003648\n",
      "Train Epoch: 4 [92480/96000 (96%)]\tLoss: 0.014958\n",
      "Train Epoch: 4 [92800/96000 (97%)]\tLoss: 0.000889\n",
      "Train Epoch: 4 [93120/96000 (97%)]\tLoss: 0.001596\n",
      "Train Epoch: 4 [93440/96000 (97%)]\tLoss: 0.003245\n",
      "Train Epoch: 4 [93760/96000 (98%)]\tLoss: 0.003782\n",
      "Train Epoch: 4 [94080/96000 (98%)]\tLoss: 0.002057\n",
      "Train Epoch: 4 [94400/96000 (98%)]\tLoss: 0.001366\n",
      "Train Epoch: 4 [94720/96000 (99%)]\tLoss: 0.004816\n",
      "Train Epoch: 4 [95040/96000 (99%)]\tLoss: 0.002618\n",
      "Train Epoch: 4 [95360/96000 (99%)]\tLoss: 0.003333\n",
      "Train Epoch: 4 [95680/96000 (100%)]\tLoss: 0.001968\n",
      "\n",
      "Test set: Average loss: 0.0642, Accuracy: 3933/4000 (98.000%)\n",
      "\n",
      "Train Epoch: 5 [0/96000 (0%)]\tLoss: 0.011358\n",
      "Train Epoch: 5 [320/96000 (0%)]\tLoss: 0.028166\n",
      "Train Epoch: 5 [640/96000 (1%)]\tLoss: 0.000744\n",
      "Train Epoch: 5 [960/96000 (1%)]\tLoss: 0.002722\n",
      "Train Epoch: 5 [1280/96000 (1%)]\tLoss: 0.001680\n",
      "Train Epoch: 5 [1600/96000 (2%)]\tLoss: 0.000588\n",
      "Train Epoch: 5 [1920/96000 (2%)]\tLoss: 0.000479\n",
      "Train Epoch: 5 [2240/96000 (2%)]\tLoss: 0.000834\n",
      "Train Epoch: 5 [2560/96000 (3%)]\tLoss: 0.017120\n",
      "Train Epoch: 5 [2880/96000 (3%)]\tLoss: 0.003651\n",
      "Train Epoch: 5 [3200/96000 (3%)]\tLoss: 0.001850\n",
      "Train Epoch: 5 [3520/96000 (4%)]\tLoss: 0.003095\n",
      "Train Epoch: 5 [3840/96000 (4%)]\tLoss: 0.179979\n",
      "Train Epoch: 5 [4160/96000 (4%)]\tLoss: 0.010691\n",
      "Train Epoch: 5 [4480/96000 (5%)]\tLoss: 0.002394\n",
      "Train Epoch: 5 [4800/96000 (5%)]\tLoss: 0.016975\n",
      "Train Epoch: 5 [5120/96000 (5%)]\tLoss: 0.177857\n",
      "Train Epoch: 5 [5440/96000 (6%)]\tLoss: 0.002390\n",
      "Train Epoch: 5 [5760/96000 (6%)]\tLoss: 0.011966\n",
      "Train Epoch: 5 [6080/96000 (6%)]\tLoss: 0.006885\n",
      "Train Epoch: 5 [6400/96000 (7%)]\tLoss: 0.002161\n",
      "Train Epoch: 5 [6720/96000 (7%)]\tLoss: 0.005618\n",
      "Train Epoch: 5 [7040/96000 (7%)]\tLoss: 0.048020\n",
      "Train Epoch: 5 [7360/96000 (8%)]\tLoss: 0.006144\n",
      "Train Epoch: 5 [7680/96000 (8%)]\tLoss: 0.003880\n",
      "Train Epoch: 5 [8000/96000 (8%)]\tLoss: 0.017743\n",
      "Train Epoch: 5 [8320/96000 (9%)]\tLoss: 0.003972\n",
      "Train Epoch: 5 [8640/96000 (9%)]\tLoss: 0.001345\n",
      "Train Epoch: 5 [8960/96000 (9%)]\tLoss: 0.003409\n",
      "Train Epoch: 5 [9280/96000 (10%)]\tLoss: 0.000932\n",
      "Train Epoch: 5 [9600/96000 (10%)]\tLoss: 0.029927\n",
      "Train Epoch: 5 [9920/96000 (10%)]\tLoss: 0.000960\n",
      "Train Epoch: 5 [10240/96000 (11%)]\tLoss: 0.004228\n",
      "Train Epoch: 5 [10560/96000 (11%)]\tLoss: 0.000373\n",
      "Train Epoch: 5 [10880/96000 (11%)]\tLoss: 0.000803\n",
      "Train Epoch: 5 [11200/96000 (12%)]\tLoss: 0.005004\n",
      "Train Epoch: 5 [11520/96000 (12%)]\tLoss: 0.001778\n",
      "Train Epoch: 5 [11840/96000 (12%)]\tLoss: 0.018626\n",
      "Train Epoch: 5 [12160/96000 (13%)]\tLoss: 0.001490\n",
      "Train Epoch: 5 [12480/96000 (13%)]\tLoss: 0.000987\n",
      "Train Epoch: 5 [12800/96000 (13%)]\tLoss: 0.005302\n",
      "Train Epoch: 5 [13120/96000 (14%)]\tLoss: 0.012145\n",
      "Train Epoch: 5 [13440/96000 (14%)]\tLoss: 0.002763\n",
      "Train Epoch: 5 [13760/96000 (14%)]\tLoss: 0.026112\n",
      "Train Epoch: 5 [14080/96000 (15%)]\tLoss: 0.056066\n",
      "Train Epoch: 5 [14400/96000 (15%)]\tLoss: 0.006123\n",
      "Train Epoch: 5 [14720/96000 (15%)]\tLoss: 0.103966\n",
      "Train Epoch: 5 [15040/96000 (16%)]\tLoss: 0.008238\n",
      "Train Epoch: 5 [15360/96000 (16%)]\tLoss: 0.003109\n",
      "Train Epoch: 5 [15680/96000 (16%)]\tLoss: 0.004619\n",
      "Train Epoch: 5 [16000/96000 (17%)]\tLoss: 0.007025\n",
      "Train Epoch: 5 [16320/96000 (17%)]\tLoss: 0.004423\n",
      "Train Epoch: 5 [16640/96000 (17%)]\tLoss: 0.002275\n",
      "Train Epoch: 5 [16960/96000 (18%)]\tLoss: 0.062637\n",
      "Train Epoch: 5 [17280/96000 (18%)]\tLoss: 0.102579\n",
      "Train Epoch: 5 [17600/96000 (18%)]\tLoss: 0.000949\n",
      "Train Epoch: 5 [17920/96000 (19%)]\tLoss: 0.021270\n",
      "Train Epoch: 5 [18240/96000 (19%)]\tLoss: 0.006647\n",
      "Train Epoch: 5 [18560/96000 (19%)]\tLoss: 0.000396\n",
      "Train Epoch: 5 [18880/96000 (20%)]\tLoss: 0.031898\n",
      "Train Epoch: 5 [19200/96000 (20%)]\tLoss: 0.095266\n",
      "Train Epoch: 5 [19520/96000 (20%)]\tLoss: 0.003613\n",
      "Train Epoch: 5 [19840/96000 (21%)]\tLoss: 0.000114\n",
      "Train Epoch: 5 [20160/96000 (21%)]\tLoss: 0.000477\n",
      "Train Epoch: 5 [20480/96000 (21%)]\tLoss: 0.000625\n",
      "Train Epoch: 5 [20800/96000 (22%)]\tLoss: 0.005970\n",
      "Train Epoch: 5 [21120/96000 (22%)]\tLoss: 0.002240\n",
      "Train Epoch: 5 [21440/96000 (22%)]\tLoss: 0.026542\n",
      "Train Epoch: 5 [21760/96000 (23%)]\tLoss: 0.004382\n",
      "Train Epoch: 5 [22080/96000 (23%)]\tLoss: 0.000438\n",
      "Train Epoch: 5 [22400/96000 (23%)]\tLoss: 0.002842\n",
      "Train Epoch: 5 [22720/96000 (24%)]\tLoss: 0.003718\n",
      "Train Epoch: 5 [23040/96000 (24%)]\tLoss: 0.001104\n",
      "Train Epoch: 5 [23360/96000 (24%)]\tLoss: 0.000532\n",
      "Train Epoch: 5 [23680/96000 (25%)]\tLoss: 0.005469\n",
      "Train Epoch: 5 [24000/96000 (25%)]\tLoss: 0.000288\n",
      "Train Epoch: 5 [24320/96000 (25%)]\tLoss: 0.008409\n",
      "Train Epoch: 5 [24640/96000 (26%)]\tLoss: 0.000489\n",
      "Train Epoch: 5 [24960/96000 (26%)]\tLoss: 0.000288\n",
      "Train Epoch: 5 [25280/96000 (26%)]\tLoss: 0.002299\n",
      "Train Epoch: 5 [25600/96000 (27%)]\tLoss: 0.194023\n",
      "Train Epoch: 5 [25920/96000 (27%)]\tLoss: 0.000838\n",
      "Train Epoch: 5 [26240/96000 (27%)]\tLoss: 0.003724\n",
      "Train Epoch: 5 [26560/96000 (28%)]\tLoss: 0.057910\n",
      "Train Epoch: 5 [26880/96000 (28%)]\tLoss: 0.002594\n",
      "Train Epoch: 5 [27200/96000 (28%)]\tLoss: 0.004334\n",
      "Train Epoch: 5 [27520/96000 (29%)]\tLoss: 0.021590\n",
      "Train Epoch: 5 [27840/96000 (29%)]\tLoss: 0.000594\n",
      "Train Epoch: 5 [28160/96000 (29%)]\tLoss: 0.003524\n",
      "Train Epoch: 5 [28480/96000 (30%)]\tLoss: 0.050486\n",
      "Train Epoch: 5 [28800/96000 (30%)]\tLoss: 0.027142\n",
      "Train Epoch: 5 [29120/96000 (30%)]\tLoss: 0.003369\n",
      "Train Epoch: 5 [29440/96000 (31%)]\tLoss: 0.000481\n",
      "Train Epoch: 5 [29760/96000 (31%)]\tLoss: 0.003505\n",
      "Train Epoch: 5 [30080/96000 (31%)]\tLoss: 0.001834\n",
      "Train Epoch: 5 [30400/96000 (32%)]\tLoss: 0.002291\n",
      "Train Epoch: 5 [30720/96000 (32%)]\tLoss: 0.002319\n",
      "Train Epoch: 5 [31040/96000 (32%)]\tLoss: 0.000736\n",
      "Train Epoch: 5 [31360/96000 (33%)]\tLoss: 0.009909\n",
      "Train Epoch: 5 [31680/96000 (33%)]\tLoss: 0.002416\n",
      "Train Epoch: 5 [32000/96000 (33%)]\tLoss: 0.002173\n",
      "Train Epoch: 5 [32320/96000 (34%)]\tLoss: 0.000340\n",
      "Train Epoch: 5 [32640/96000 (34%)]\tLoss: 0.000800\n",
      "Train Epoch: 5 [32960/96000 (34%)]\tLoss: 0.002533\n",
      "Train Epoch: 5 [33280/96000 (35%)]\tLoss: 0.000560\n",
      "Train Epoch: 5 [33600/96000 (35%)]\tLoss: 0.005185\n",
      "Train Epoch: 5 [33920/96000 (35%)]\tLoss: 0.020613\n",
      "Train Epoch: 5 [34240/96000 (36%)]\tLoss: 0.003875\n",
      "Train Epoch: 5 [34560/96000 (36%)]\tLoss: 0.001568\n",
      "Train Epoch: 5 [34880/96000 (36%)]\tLoss: 0.008244\n",
      "Train Epoch: 5 [35200/96000 (37%)]\tLoss: 0.005657\n",
      "Train Epoch: 5 [35520/96000 (37%)]\tLoss: 0.001431\n",
      "Train Epoch: 5 [35840/96000 (37%)]\tLoss: 0.010236\n",
      "Train Epoch: 5 [36160/96000 (38%)]\tLoss: 0.007129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [36480/96000 (38%)]\tLoss: 0.054313\n",
      "Train Epoch: 5 [36800/96000 (38%)]\tLoss: 0.002443\n",
      "Train Epoch: 5 [37120/96000 (39%)]\tLoss: 0.001873\n",
      "Train Epoch: 5 [37440/96000 (39%)]\tLoss: 0.000382\n",
      "Train Epoch: 5 [37760/96000 (39%)]\tLoss: 0.003804\n",
      "Train Epoch: 5 [38080/96000 (40%)]\tLoss: 0.000994\n",
      "Train Epoch: 5 [38400/96000 (40%)]\tLoss: 0.004276\n",
      "Train Epoch: 5 [38720/96000 (40%)]\tLoss: 0.000875\n",
      "Train Epoch: 5 [39040/96000 (41%)]\tLoss: 0.043564\n",
      "Train Epoch: 5 [39360/96000 (41%)]\tLoss: 0.004292\n",
      "Train Epoch: 5 [39680/96000 (41%)]\tLoss: 0.013403\n",
      "Train Epoch: 5 [40000/96000 (42%)]\tLoss: 0.001047\n",
      "Train Epoch: 5 [40320/96000 (42%)]\tLoss: 0.009252\n",
      "Train Epoch: 5 [40640/96000 (42%)]\tLoss: 0.208627\n",
      "Train Epoch: 5 [40960/96000 (43%)]\tLoss: 0.139538\n",
      "Train Epoch: 5 [41280/96000 (43%)]\tLoss: 0.000393\n",
      "Train Epoch: 5 [41600/96000 (43%)]\tLoss: 0.000500\n",
      "Train Epoch: 5 [41920/96000 (44%)]\tLoss: 0.000346\n",
      "Train Epoch: 5 [42240/96000 (44%)]\tLoss: 0.004735\n",
      "Train Epoch: 5 [42560/96000 (44%)]\tLoss: 0.131079\n",
      "Train Epoch: 5 [42880/96000 (45%)]\tLoss: 0.027885\n",
      "Train Epoch: 5 [43200/96000 (45%)]\tLoss: 0.000463\n",
      "Train Epoch: 5 [43520/96000 (45%)]\tLoss: 0.005215\n",
      "Train Epoch: 5 [43840/96000 (46%)]\tLoss: 0.002904\n",
      "Train Epoch: 5 [44160/96000 (46%)]\tLoss: 0.002257\n",
      "Train Epoch: 5 [44480/96000 (46%)]\tLoss: 0.000893\n",
      "Train Epoch: 5 [44800/96000 (47%)]\tLoss: 0.006342\n",
      "Train Epoch: 5 [45120/96000 (47%)]\tLoss: 0.002177\n",
      "Train Epoch: 5 [45440/96000 (47%)]\tLoss: 0.001904\n",
      "Train Epoch: 5 [45760/96000 (48%)]\tLoss: 0.005529\n",
      "Train Epoch: 5 [46080/96000 (48%)]\tLoss: 0.005639\n",
      "Train Epoch: 5 [46400/96000 (48%)]\tLoss: 0.002280\n",
      "Train Epoch: 5 [46720/96000 (49%)]\tLoss: 0.001937\n",
      "Train Epoch: 5 [47040/96000 (49%)]\tLoss: 0.002485\n",
      "Train Epoch: 5 [47360/96000 (49%)]\tLoss: 0.001423\n",
      "Train Epoch: 5 [47680/96000 (50%)]\tLoss: 0.016730\n",
      "Train Epoch: 5 [48000/96000 (50%)]\tLoss: 0.007012\n",
      "Train Epoch: 5 [48320/96000 (50%)]\tLoss: 0.000457\n",
      "Train Epoch: 5 [48640/96000 (51%)]\tLoss: 0.001193\n",
      "Train Epoch: 5 [48960/96000 (51%)]\tLoss: 0.005521\n",
      "Train Epoch: 5 [49280/96000 (51%)]\tLoss: 0.000247\n",
      "Train Epoch: 5 [49600/96000 (52%)]\tLoss: 0.028959\n",
      "Train Epoch: 5 [49920/96000 (52%)]\tLoss: 0.000571\n",
      "Train Epoch: 5 [50240/96000 (52%)]\tLoss: 0.000888\n",
      "Train Epoch: 5 [50560/96000 (53%)]\tLoss: 0.009121\n",
      "Train Epoch: 5 [50880/96000 (53%)]\tLoss: 0.014322\n",
      "Train Epoch: 5 [51200/96000 (53%)]\tLoss: 0.000440\n",
      "Train Epoch: 5 [51520/96000 (54%)]\tLoss: 0.001157\n",
      "Train Epoch: 5 [51840/96000 (54%)]\tLoss: 0.001342\n",
      "Train Epoch: 5 [52160/96000 (54%)]\tLoss: 0.000812\n",
      "Train Epoch: 5 [52480/96000 (55%)]\tLoss: 0.029006\n",
      "Train Epoch: 5 [52800/96000 (55%)]\tLoss: 0.001066\n",
      "Train Epoch: 5 [53120/96000 (55%)]\tLoss: 0.000709\n",
      "Train Epoch: 5 [53440/96000 (56%)]\tLoss: 0.012007\n",
      "Train Epoch: 5 [53760/96000 (56%)]\tLoss: 0.020433\n",
      "Train Epoch: 5 [54080/96000 (56%)]\tLoss: 0.054303\n",
      "Train Epoch: 5 [54400/96000 (57%)]\tLoss: 0.003352\n",
      "Train Epoch: 5 [54720/96000 (57%)]\tLoss: 0.002157\n",
      "Train Epoch: 5 [55040/96000 (57%)]\tLoss: 0.001179\n",
      "Train Epoch: 5 [55360/96000 (58%)]\tLoss: 0.001378\n",
      "Train Epoch: 5 [55680/96000 (58%)]\tLoss: 0.006266\n",
      "Train Epoch: 5 [56000/96000 (58%)]\tLoss: 0.011599\n",
      "Train Epoch: 5 [56320/96000 (59%)]\tLoss: 0.097180\n",
      "Train Epoch: 5 [56640/96000 (59%)]\tLoss: 0.001102\n",
      "Train Epoch: 5 [56960/96000 (59%)]\tLoss: 0.004045\n",
      "Train Epoch: 5 [57280/96000 (60%)]\tLoss: 0.001315\n",
      "Train Epoch: 5 [57600/96000 (60%)]\tLoss: 0.002030\n",
      "Train Epoch: 5 [57920/96000 (60%)]\tLoss: 0.015465\n",
      "Train Epoch: 5 [58240/96000 (61%)]\tLoss: 0.005411\n",
      "Train Epoch: 5 [58560/96000 (61%)]\tLoss: 0.006169\n",
      "Train Epoch: 5 [58880/96000 (61%)]\tLoss: 0.000190\n",
      "Train Epoch: 5 [59200/96000 (62%)]\tLoss: 0.000963\n",
      "Train Epoch: 5 [59520/96000 (62%)]\tLoss: 0.003479\n",
      "Train Epoch: 5 [59840/96000 (62%)]\tLoss: 0.006203\n",
      "Train Epoch: 5 [60160/96000 (63%)]\tLoss: 0.003506\n",
      "Train Epoch: 5 [60480/96000 (63%)]\tLoss: 0.003882\n",
      "Train Epoch: 5 [60800/96000 (63%)]\tLoss: 0.006191\n",
      "Train Epoch: 5 [61120/96000 (64%)]\tLoss: 0.001230\n",
      "Train Epoch: 5 [61440/96000 (64%)]\tLoss: 0.003073\n",
      "Train Epoch: 5 [61760/96000 (64%)]\tLoss: 0.001743\n",
      "Train Epoch: 5 [62080/96000 (65%)]\tLoss: 0.019821\n",
      "Train Epoch: 5 [62400/96000 (65%)]\tLoss: 0.021878\n",
      "Train Epoch: 5 [62720/96000 (65%)]\tLoss: 0.000907\n",
      "Train Epoch: 5 [63040/96000 (66%)]\tLoss: 0.000407\n",
      "Train Epoch: 5 [63360/96000 (66%)]\tLoss: 0.023324\n",
      "Train Epoch: 5 [63680/96000 (66%)]\tLoss: 0.001113\n",
      "Train Epoch: 5 [64000/96000 (67%)]\tLoss: 0.002752\n",
      "Train Epoch: 5 [64320/96000 (67%)]\tLoss: 0.002229\n",
      "Train Epoch: 5 [64640/96000 (67%)]\tLoss: 0.064406\n",
      "Train Epoch: 5 [64960/96000 (68%)]\tLoss: 0.000947\n",
      "Train Epoch: 5 [65280/96000 (68%)]\tLoss: 0.000487\n",
      "Train Epoch: 5 [65600/96000 (68%)]\tLoss: 0.000648\n",
      "Train Epoch: 5 [65920/96000 (69%)]\tLoss: 0.000838\n",
      "Train Epoch: 5 [66240/96000 (69%)]\tLoss: 0.173589\n",
      "Train Epoch: 5 [66560/96000 (69%)]\tLoss: 0.002759\n",
      "Train Epoch: 5 [66880/96000 (70%)]\tLoss: 0.001373\n",
      "Train Epoch: 5 [67200/96000 (70%)]\tLoss: 0.000745\n",
      "Train Epoch: 5 [67520/96000 (70%)]\tLoss: 0.002987\n",
      "Train Epoch: 5 [67840/96000 (71%)]\tLoss: 0.007495\n",
      "Train Epoch: 5 [68160/96000 (71%)]\tLoss: 0.008159\n",
      "Train Epoch: 5 [68480/96000 (71%)]\tLoss: 0.136294\n",
      "Train Epoch: 5 [68800/96000 (72%)]\tLoss: 0.141762\n",
      "Train Epoch: 5 [69120/96000 (72%)]\tLoss: 0.006593\n",
      "Train Epoch: 5 [69440/96000 (72%)]\tLoss: 0.033612\n",
      "Train Epoch: 5 [69760/96000 (73%)]\tLoss: 0.000561\n",
      "Train Epoch: 5 [70080/96000 (73%)]\tLoss: 0.000365\n",
      "Train Epoch: 5 [70400/96000 (73%)]\tLoss: 0.002183\n",
      "Train Epoch: 5 [70720/96000 (74%)]\tLoss: 0.005163\n",
      "Train Epoch: 5 [71040/96000 (74%)]\tLoss: 0.017310\n",
      "Train Epoch: 5 [71360/96000 (74%)]\tLoss: 0.001171\n",
      "Train Epoch: 5 [71680/96000 (75%)]\tLoss: 0.000602\n",
      "Train Epoch: 5 [72000/96000 (75%)]\tLoss: 0.000287\n",
      "Train Epoch: 5 [72320/96000 (75%)]\tLoss: 0.000712\n",
      "Train Epoch: 5 [72640/96000 (76%)]\tLoss: 0.013483\n",
      "Train Epoch: 5 [72960/96000 (76%)]\tLoss: 0.000220\n",
      "Train Epoch: 5 [73280/96000 (76%)]\tLoss: 0.000324\n",
      "Train Epoch: 5 [73600/96000 (77%)]\tLoss: 0.004190\n",
      "Train Epoch: 5 [73920/96000 (77%)]\tLoss: 0.051549\n",
      "Train Epoch: 5 [74240/96000 (77%)]\tLoss: 0.021297\n",
      "Train Epoch: 5 [74560/96000 (78%)]\tLoss: 0.000615\n",
      "Train Epoch: 5 [74880/96000 (78%)]\tLoss: 0.002303\n",
      "Train Epoch: 5 [75200/96000 (78%)]\tLoss: 0.010807\n",
      "Train Epoch: 5 [75520/96000 (79%)]\tLoss: 0.000455\n",
      "Train Epoch: 5 [75840/96000 (79%)]\tLoss: 0.003335\n",
      "Train Epoch: 5 [76160/96000 (79%)]\tLoss: 0.007836\n",
      "Train Epoch: 5 [76480/96000 (80%)]\tLoss: 0.001228\n",
      "Train Epoch: 5 [76800/96000 (80%)]\tLoss: 0.000900\n",
      "Train Epoch: 5 [77120/96000 (80%)]\tLoss: 0.003015\n",
      "Train Epoch: 5 [77440/96000 (81%)]\tLoss: 0.001396\n",
      "Train Epoch: 5 [77760/96000 (81%)]\tLoss: 0.012601\n",
      "Train Epoch: 5 [78080/96000 (81%)]\tLoss: 0.001714\n",
      "Train Epoch: 5 [78400/96000 (82%)]\tLoss: 0.000528\n",
      "Train Epoch: 5 [78720/96000 (82%)]\tLoss: 0.010342\n",
      "Train Epoch: 5 [79040/96000 (82%)]\tLoss: 0.001606\n",
      "Train Epoch: 5 [79360/96000 (83%)]\tLoss: 0.000229\n",
      "Train Epoch: 5 [79680/96000 (83%)]\tLoss: 0.002001\n",
      "Train Epoch: 5 [80000/96000 (83%)]\tLoss: 0.000834\n",
      "Train Epoch: 5 [80320/96000 (84%)]\tLoss: 0.001158\n",
      "Train Epoch: 5 [80640/96000 (84%)]\tLoss: 0.000920\n",
      "Train Epoch: 5 [80960/96000 (84%)]\tLoss: 0.065105\n",
      "Train Epoch: 5 [81280/96000 (85%)]\tLoss: 0.152506\n",
      "Train Epoch: 5 [81600/96000 (85%)]\tLoss: 0.000501\n",
      "Train Epoch: 5 [81920/96000 (85%)]\tLoss: 0.002437\n",
      "Train Epoch: 5 [82240/96000 (86%)]\tLoss: 0.001108\n",
      "Train Epoch: 5 [82560/96000 (86%)]\tLoss: 0.023343\n",
      "Train Epoch: 5 [82880/96000 (86%)]\tLoss: 0.000430\n",
      "Train Epoch: 5 [83200/96000 (87%)]\tLoss: 0.018084\n",
      "Train Epoch: 5 [83520/96000 (87%)]\tLoss: 0.041075\n",
      "Train Epoch: 5 [83840/96000 (87%)]\tLoss: 0.000842\n",
      "Train Epoch: 5 [84160/96000 (88%)]\tLoss: 0.004306\n",
      "Train Epoch: 5 [84480/96000 (88%)]\tLoss: 0.000729\n",
      "Train Epoch: 5 [84800/96000 (88%)]\tLoss: 0.000596\n",
      "Train Epoch: 5 [85120/96000 (89%)]\tLoss: 0.075294\n",
      "Train Epoch: 5 [85440/96000 (89%)]\tLoss: 0.001431\n",
      "Train Epoch: 5 [85760/96000 (89%)]\tLoss: 0.064420\n",
      "Train Epoch: 5 [86080/96000 (90%)]\tLoss: 0.002324\n",
      "Train Epoch: 5 [86400/96000 (90%)]\tLoss: 0.003664\n",
      "Train Epoch: 5 [86720/96000 (90%)]\tLoss: 0.000609\n",
      "Train Epoch: 5 [87040/96000 (91%)]\tLoss: 0.042655\n",
      "Train Epoch: 5 [87360/96000 (91%)]\tLoss: 0.000806\n",
      "Train Epoch: 5 [87680/96000 (91%)]\tLoss: 0.002169\n",
      "Train Epoch: 5 [88000/96000 (92%)]\tLoss: 0.011032\n",
      "Train Epoch: 5 [88320/96000 (92%)]\tLoss: 0.000778\n",
      "Train Epoch: 5 [88640/96000 (92%)]\tLoss: 0.000228\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [88960/96000 (93%)]\tLoss: 0.008368\n",
      "Train Epoch: 5 [89280/96000 (93%)]\tLoss: 0.005040\n",
      "Train Epoch: 5 [89600/96000 (93%)]\tLoss: 0.000952\n",
      "Train Epoch: 5 [89920/96000 (94%)]\tLoss: 0.000625\n",
      "Train Epoch: 5 [90240/96000 (94%)]\tLoss: 0.082785\n",
      "Train Epoch: 5 [90560/96000 (94%)]\tLoss: 0.006766\n",
      "Train Epoch: 5 [90880/96000 (95%)]\tLoss: 0.001608\n",
      "Train Epoch: 5 [91200/96000 (95%)]\tLoss: 0.000265\n",
      "Train Epoch: 5 [91520/96000 (95%)]\tLoss: 0.010226\n",
      "Train Epoch: 5 [91840/96000 (96%)]\tLoss: 0.002886\n",
      "Train Epoch: 5 [92160/96000 (96%)]\tLoss: 0.026167\n",
      "Train Epoch: 5 [92480/96000 (96%)]\tLoss: 0.000995\n",
      "Train Epoch: 5 [92800/96000 (97%)]\tLoss: 0.002390\n",
      "Train Epoch: 5 [93120/96000 (97%)]\tLoss: 0.000897\n",
      "Train Epoch: 5 [93440/96000 (97%)]\tLoss: 0.000288\n",
      "Train Epoch: 5 [93760/96000 (98%)]\tLoss: 0.000353\n",
      "Train Epoch: 5 [94080/96000 (98%)]\tLoss: 0.023201\n",
      "Train Epoch: 5 [94400/96000 (98%)]\tLoss: 0.010870\n",
      "Train Epoch: 5 [94720/96000 (99%)]\tLoss: 0.007315\n",
      "Train Epoch: 5 [95040/96000 (99%)]\tLoss: 0.043622\n",
      "Train Epoch: 5 [95360/96000 (99%)]\tLoss: 0.007057\n",
      "Train Epoch: 5 [95680/96000 (100%)]\tLoss: 0.002038\n",
      "\n",
      "Test set: Average loss: 0.0631, Accuracy: 3926/4000 (98.000%)\n",
      "\n",
      "CPU times: user 37min 12s, sys: 34.4 s, total: 37min 46s\n",
      "Wall time: 19min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(1, 5 + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
