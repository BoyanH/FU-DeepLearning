{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN for recognizing genetic code\n",
    "\n",
    "#### Task\n",
    "In this challenge, we to train a classifier for sequences of genetic code.\n",
    "Each sequence is represented by a string of letters [‘A’, ‘C’, ‘G’, ’T’] and belongs to one of five categories/classes labelled [0,…,4].\n",
    "\n",
    "For training purposes, you will find 400 labelled sequences, each of length 400 characters (sequences: data_x, labels: data_y).\n",
    "\n",
    "To validate your model, you have a further 100 labelled sequences (val_x, val_y) with 1200 characters each.\n",
    "\n",
    "Finally, you have 250 unlabelled sequences (test_x, 2000 characters) which need to be classified.\n",
    "\n",
    "Hint: Training recurrent networks is very expensive! Do not start working on this challenge to late or you will not manage to finish in time.\n",
    "\n",
    "#### Approach\n",
    "\n",
    "We will use LSTM units in a recurrent NN primarily based on this paper -> https://arxiv.org/pdf/1608.03644.pdf .\n",
    "The architecture is a combination of convolutional layers and recurrent LSTM layers.\n",
    "One can clearly see in this paper, that CNNs outperform RNNs with LSTM units in this task, but we are using RNNs for the sake of learning here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, LSTM, Reshape, Flatten, \\\n",
    "                         Conv2D, MaxPooling2D, BatchNormalization, Bidirectional\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, EarlyStopping\n",
    "\n",
    "# from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "K.set_image_data_format(\"channels_last\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x shape: (400,)\n",
      "train_y shape: (400,)\n",
      "val_x shape: (100,)\n",
      "val_y shape: (100,)\n",
      "test_x shape: (250,)\n"
     ]
    }
   ],
   "source": [
    "with np.load('./data/rnn-challenge-data.npz') as f:\n",
    "    train_x = f['data_x']\n",
    "    train_y = f['data_y']\n",
    "    val_x = f['val_x']\n",
    "    val_y = f['val_y']\n",
    "    test_x = f['test_x']\n",
    "    \n",
    "print('train_x shape: {}'.format(train_x.shape))\n",
    "print('train_y shape: {}'.format(train_y.shape))\n",
    "print('val_x shape: {}'.format(val_x.shape))\n",
    "print('val_y shape: {}'.format(val_y.shape))\n",
    "print('test_x shape: {}'.format(test_x.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's see what's inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X: CTAGCTGAGCTACTGAGCTACAGTTGACTGACCAGTCAGTGCTAGCTACTGACAGTCTGACAGTTGACCTGACTGATGACCAGTCTAGCAGTGCTACTAGCTAGGCTACAGTCAGTTGACCAGTCTGACAGTCAGTCTGACTGACAGTCAGTCTAGGCTATGACCTGACTGATGACCTGACTGACTGACAGTCTGACTGATGACGCTATGACCTGACTAGCTAGCAGTTGACTGACCTGACAGTGCTACTAGCAGTTGACCAGTGCTACAGTCTGATGACTGACCTGACAGTCTAGGCTACAGTTGACCTGACAGTCAGTGCTACTGACAGTCTAGTGACCAGTCAGTCAGTTGACCTGACTAGCAGTTGACGCTATGACCAGTCTGACAGTGCTACTAG\n",
      "y: 2\n"
     ]
    }
   ],
   "source": [
    "print('X: {}'.format(train_x[0]))\n",
    "print('y: {}'.format(train_y[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNA Code encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 4, 2000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "representations = ['A', 'C', 'G', 'T']\n",
    "max_sequence_len = 2000\n",
    "reps_len = len(representations)\n",
    "eye = np.eye(reps_len)\n",
    "\n",
    "def one_hot(X):\n",
    "    encoded = []\n",
    "    \n",
    "    for code in X:\n",
    "#         encoded.append([representations.index(c) for c in code])\n",
    "        encoded.append(np.vstack([\n",
    "            np.array([eye[representations.index(c)] for c in code]),\n",
    "            np.zeros((max_sequence_len - len(code), reps_len))\n",
    "        ]\n",
    "        ))\n",
    "\n",
    "        # TODO: do a better padding\n",
    "    \n",
    "    # because of the way LSTM is implemented in keras, we need the columns to be our data points\n",
    "    # and in the rows we need all the features\n",
    "    return np.array(encoded).swapaxes(1,2)\n",
    "\n",
    "try:\n",
    "    X_train = one_hot(train_x)\n",
    "    y_train = np.eye(5)[train_y]\n",
    "    X_val = one_hot(val_x)\n",
    "    y_val = np.eye(5)[val_y]\n",
    "    X_test = one_hot(test_x)\n",
    "\n",
    "    del train_x, train_y, val_x, val_y, test_x\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    pass\n",
    "    # step already done\n",
    "    \n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 100\n",
    "sequence_len = X_train.shape[1]\n",
    "embedding_image_shape = tuple(np.array([np.sqrt(embedding_size * sequence_len)] * 2, dtype=int))\n",
    "\n",
    "conv_kernel = (9,9)\n",
    "conv_stride = (1,1)\n",
    "conv_filters = 128\n",
    "conv_padding = 'same'\n",
    "\n",
    "# pool_size = (7,7)\n",
    "# pool_stride = (2,2)\n",
    "# pool_padding = 'valid'\n",
    "\n",
    "lstm_layers = 32\n",
    "\n",
    "optimizer = Adam()\n",
    "batch_size = 32\n",
    "epochs = 150\n",
    "\n",
    "labels_count = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 4, 2000)           0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 2000, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 4, 2000, 128)      10496     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4, 2000, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 4, 2000, 128)      512       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 4, 2000, 1)        10369     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4, 2000, 1)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 4, 2000, 1)        4         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 4, 2000)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 64)                520448    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 542,154\n",
      "Trainable params: 541,896\n",
      "Non-trainable params: 258\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_input = Input(shape=X_train.shape[1:])\n",
    "x = model_input\n",
    "x = Reshape((*X_train.shape[1:], 1))(x)\n",
    "x = Conv2D(conv_filters, kernel_size=conv_kernel, padding=conv_padding, strides=conv_stride, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(1, kernel_size=conv_kernel, padding=conv_padding, strides=conv_stride, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Reshape(X_train.shape[1:])(x)\n",
    "# TODO: try merge mode\n",
    "x = Bidirectional(LSTM(lstm_layers, dropout=0.5, recurrent_dropout=0.2))(x)\n",
    "x = Dense(labels_count, activation='softmax')(x)\n",
    "\n",
    "model = Model(model_input, x, name='model')\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 4, 2000)\n",
      "Train on 400 samples, validate on 100 samples\n",
      "Epoch 1/150\n",
      "400/400 [==============================] - 92s 230ms/step - loss: 1.6477 - categorical_accuracy: 0.2225 - val_loss: 1.6437 - val_categorical_accuracy: 0.2100\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.64374, saving model to ./model/weights.hdf5\n",
      "Epoch 2/150\n",
      "400/400 [==============================] - 90s 225ms/step - loss: 1.5147 - categorical_accuracy: 0.3300 - val_loss: 1.6995 - val_categorical_accuracy: 0.2400\n",
      "\n",
      "Epoch 00002: val_loss did not improve from 1.64374\n",
      "Epoch 3/150\n",
      "400/400 [==============================] - 87s 218ms/step - loss: 1.1927 - categorical_accuracy: 0.5925 - val_loss: 1.5069 - val_categorical_accuracy: 0.2600\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.64374 to 1.50687, saving model to ./model/weights.hdf5\n",
      "Epoch 4/150\n",
      "400/400 [==============================] - 88s 220ms/step - loss: 0.7824 - categorical_accuracy: 0.7800 - val_loss: 1.0818 - val_categorical_accuracy: 0.4900\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.50687 to 1.08181, saving model to ./model/weights.hdf5\n",
      "Epoch 5/150\n",
      "400/400 [==============================] - 87s 218ms/step - loss: 0.4845 - categorical_accuracy: 0.9075 - val_loss: 0.8384 - val_categorical_accuracy: 0.7100\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.08181 to 0.83841, saving model to ./model/weights.hdf5\n",
      "Epoch 6/150\n",
      "400/400 [==============================] - 88s 219ms/step - loss: 0.2692 - categorical_accuracy: 0.9975 - val_loss: 0.7769 - val_categorical_accuracy: 0.7600\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.83841 to 0.77694, saving model to ./model/weights.hdf5\n",
      "Epoch 7/150\n",
      "400/400 [==============================] - 87s 218ms/step - loss: 0.1582 - categorical_accuracy: 0.9875 - val_loss: 0.5781 - val_categorical_accuracy: 0.8700\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.77694 to 0.57809, saving model to ./model/weights.hdf5\n",
      "Epoch 8/150\n",
      "400/400 [==============================] - 86s 216ms/step - loss: 0.0921 - categorical_accuracy: 0.9975 - val_loss: 0.5168 - val_categorical_accuracy: 0.8900\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.57809 to 0.51679, saving model to ./model/weights.hdf5\n",
      "Epoch 9/150\n",
      "400/400 [==============================] - 86s 215ms/step - loss: 0.0587 - categorical_accuracy: 1.0000 - val_loss: 0.4111 - val_categorical_accuracy: 0.9400\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.51679 to 0.41106, saving model to ./model/weights.hdf5\n",
      "Epoch 10/150\n",
      "400/400 [==============================] - 86s 215ms/step - loss: 0.0396 - categorical_accuracy: 1.0000 - val_loss: 0.4132 - val_categorical_accuracy: 0.9200\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.41106\n",
      "Epoch 11/150\n",
      "400/400 [==============================] - 86s 215ms/step - loss: 0.0304 - categorical_accuracy: 1.0000 - val_loss: 0.3748 - val_categorical_accuracy: 0.9600\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.41106 to 0.37483, saving model to ./model/weights.hdf5\n",
      "Epoch 12/150\n",
      "400/400 [==============================] - 86s 215ms/step - loss: 0.0249 - categorical_accuracy: 1.0000 - val_loss: 0.3316 - val_categorical_accuracy: 0.9700\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.37483 to 0.33160, saving model to ./model/weights.hdf5\n",
      "Epoch 13/150\n",
      "400/400 [==============================] - 86s 214ms/step - loss: 0.0185 - categorical_accuracy: 1.0000 - val_loss: 0.3054 - val_categorical_accuracy: 0.9700\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.33160 to 0.30544, saving model to ./model/weights.hdf5\n",
      "Epoch 14/150\n",
      "400/400 [==============================] - 85s 214ms/step - loss: 0.0165 - categorical_accuracy: 1.0000 - val_loss: 0.3213 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.30544\n",
      "Epoch 15/150\n",
      "400/400 [==============================] - 86s 214ms/step - loss: 0.0139 - categorical_accuracy: 1.0000 - val_loss: 0.2538 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.30544 to 0.25376, saving model to ./model/weights.hdf5\n",
      "Epoch 16/150\n",
      "400/400 [==============================] - 85s 214ms/step - loss: 0.0125 - categorical_accuracy: 1.0000 - val_loss: 0.2676 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.25376\n",
      "Epoch 17/150\n",
      "400/400 [==============================] - 86s 214ms/step - loss: 0.0110 - categorical_accuracy: 1.0000 - val_loss: 0.2507 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.25376 to 0.25073, saving model to ./model/weights.hdf5\n",
      "Epoch 18/150\n",
      "400/400 [==============================] - 85s 214ms/step - loss: 0.0093 - categorical_accuracy: 1.0000 - val_loss: 0.2590 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.25073\n",
      "Epoch 19/150\n",
      "400/400 [==============================] - 86s 214ms/step - loss: 0.0087 - categorical_accuracy: 1.0000 - val_loss: 0.2551 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.25073\n",
      "Epoch 20/150\n",
      "400/400 [==============================] - 86s 214ms/step - loss: 0.0076 - categorical_accuracy: 1.0000 - val_loss: 0.2560 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.25073\n",
      "Epoch 21/150\n",
      "400/400 [==============================] - 85s 214ms/step - loss: 0.0068 - categorical_accuracy: 1.0000 - val_loss: 0.2618 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.25073\n",
      "Epoch 22/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0061 - categorical_accuracy: 1.0000 - val_loss: 0.2389 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.25073 to 0.23887, saving model to ./model/weights.hdf5\n",
      "Epoch 23/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0056 - categorical_accuracy: 1.0000 - val_loss: 0.2616 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.23887\n",
      "Epoch 24/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0054 - categorical_accuracy: 1.0000 - val_loss: 0.2484 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.23887\n",
      "Epoch 25/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0051 - categorical_accuracy: 1.0000 - val_loss: 0.2673 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.23887\n",
      "Epoch 26/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0052 - categorical_accuracy: 1.0000 - val_loss: 0.2155 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.23887 to 0.21553, saving model to ./model/weights.hdf5\n",
      "Epoch 27/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0042 - categorical_accuracy: 1.0000 - val_loss: 0.2466 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.21553\n",
      "Epoch 28/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0037 - categorical_accuracy: 1.0000 - val_loss: 0.2549 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.21553\n",
      "Epoch 29/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0038 - categorical_accuracy: 1.0000 - val_loss: 0.2815 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.21553\n",
      "Epoch 30/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0034 - categorical_accuracy: 1.0000 - val_loss: 0.2665 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.21553\n",
      "Epoch 31/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0035 - categorical_accuracy: 1.0000 - val_loss: 0.2457 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.21553\n",
      "Epoch 32/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0031 - categorical_accuracy: 1.0000 - val_loss: 0.2278 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.21553\n",
      "Epoch 33/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 0.2522 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.21553\n",
      "Epoch 34/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0029 - categorical_accuracy: 1.0000 - val_loss: 0.2408 - val_categorical_accuracy: 0.9900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00034: val_loss did not improve from 0.21553\n",
      "Epoch 35/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0024 - categorical_accuracy: 1.0000 - val_loss: 0.2534 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.21553\n",
      "Epoch 36/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.2629 - val_categorical_accuracy: 0.9700\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.21553\n",
      "Epoch 37/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 0.2566 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.21553\n",
      "Epoch 38/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 0.2446 - val_categorical_accuracy: 0.9900\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.21553\n",
      "Epoch 39/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 0.2633 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.21553\n",
      "Epoch 40/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0019 - categorical_accuracy: 1.0000 - val_loss: 0.2747 - val_categorical_accuracy: 0.9700\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.21553\n",
      "Epoch 41/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0021 - categorical_accuracy: 1.0000 - val_loss: 0.2697 - val_categorical_accuracy: 0.9800\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.21553\n",
      "Epoch 42/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0027 - categorical_accuracy: 1.0000 - val_loss: 0.2868 - val_categorical_accuracy: 0.9700\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.21553\n",
      "Epoch 43/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0088 - categorical_accuracy: 0.9975 - val_loss: 0.4956 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.21553\n",
      "Epoch 44/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0043 - categorical_accuracy: 1.0000 - val_loss: 0.4119 - val_categorical_accuracy: 0.8600\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.21553\n",
      "Epoch 45/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0032 - categorical_accuracy: 1.0000 - val_loss: 0.4865 - val_categorical_accuracy: 0.8100\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.21553\n",
      "Epoch 46/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0023 - categorical_accuracy: 1.0000 - val_loss: 0.4667 - val_categorical_accuracy: 0.8000\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.21553\n",
      "Epoch 47/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 0.3867 - val_categorical_accuracy: 0.8400\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.21553\n",
      "Epoch 48/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 0.4159 - val_categorical_accuracy: 0.8200\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.21553\n",
      "Epoch 49/150\n",
      "400/400 [==============================] - 84s 210ms/step - loss: 0.0016 - categorical_accuracy: 1.0000 - val_loss: 0.3600 - val_categorical_accuracy: 0.8700\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.21553\n",
      "Epoch 50/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0015 - categorical_accuracy: 1.0000 - val_loss: 0.3346 - val_categorical_accuracy: 0.9100\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.21553\n",
      "Epoch 51/150\n",
      "400/400 [==============================] - 84s 211ms/step - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 0.3451 - val_categorical_accuracy: 0.8800\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.21553\n"
     ]
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='./model/weights.hdf5', verbose=1, save_best_only=True)\n",
    "tensorboard = TensorBoard(log_dir='./stats/dim_reduction')\n",
    "print(X_train.shape)\n",
    "stop = EarlyStopping(monitor=\"val_loss\", min_delta=0.0001, patience=25, mode=\"min\")\n",
    "history = model.fit(X_train, y_train,\n",
    "                batch_size=batch_size,\n",
    "                epochs=epochs,\n",
    "                verbose=1,\n",
    "                validation_data=(X_val, y_val),\n",
    "                callbacks=[checkpointer, tensorboard, stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 5s 50ms/step\n",
      "Accuracy: 0.99\n"
     ]
    }
   ],
   "source": [
    "model.load_weights('./model/weights.hdf5')\n",
    "loss, acc = model.evaluate(X_val, y_val)\n",
    "print('Accuracy: {}'.format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions and check confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.04641771 0.02749521 0.7219298  0.1031497  0.1010076 ]\n",
      " [0.03334371 0.04376873 0.62636894 0.03993057 0.25658798]\n",
      " [0.02275329 0.18065219 0.35334268 0.4238008  0.01945102]\n",
      " [0.03114861 0.1328021  0.48470274 0.33025292 0.02109354]\n",
      " [0.1473253  0.0177479  0.66418207 0.06035194 0.11039281]]\n",
      "[2 2 3 2 2]\n"
     ]
    }
   ],
   "source": [
    "one_hot_predictions = model.predict(X_test)\n",
    "predictions = np.argmax(one_hot_predictions, axis=1)\n",
    "print(one_hot_predictions[:5])\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('prediction.npy', predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl-keras",
   "language": "python",
   "name": "dl-keras"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
